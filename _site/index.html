<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>R-Project</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R-Project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">R-Project</h1>

</div>


<pre class="r"><code># Importing the library

library(lubridate)</code></pre>
<pre><code>## 
## Attaching package: &#39;lubridate&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     date, intersect, setdiff, union</code></pre>
<pre class="r"><code>library(stringr)
library(tidyverse)</code></pre>
<pre><code>## ── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ──
## ✔ dplyr   1.1.4     ✔ readr   2.1.5
## ✔ forcats 1.0.0     ✔ tibble  3.2.1
## ✔ ggplot2 3.5.0     ✔ tidyr   1.3.1
## ✔ purrr   1.0.2</code></pre>
<pre><code>## ── Conflicts ──────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
<pre class="r"><code>library(reshape2)</code></pre>
<pre><code>## Warning: package &#39;reshape2&#39; was built under R version 4.3.3</code></pre>
<pre><code>## 
## Attaching package: &#39;reshape2&#39;
## 
## The following object is masked from &#39;package:tidyr&#39;:
## 
##     smiths</code></pre>
<pre class="r"><code>library(psych)</code></pre>
<pre><code>## Warning: package &#39;psych&#39; was built under R version 4.3.3</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;
## 
## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>library(caTools)</code></pre>
<pre><code>## Warning: package &#39;caTools&#39; was built under R version 4.3.3</code></pre>
<pre class="r"><code>library(e1071)</code></pre>
<pre><code>## Warning: package &#39;e1071&#39; was built under R version 4.3.3</code></pre>
<pre class="r"><code>library(lmtest)</code></pre>
<pre><code>## Warning: package &#39;lmtest&#39; was built under R version 4.3.3</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## Warning: package &#39;zoo&#39; was built under R version 4.3.3</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>library(rpart)</code></pre>
<pre><code>## Warning: package &#39;rpart&#39; was built under R version 4.3.3</code></pre>
<pre class="r"><code>library(corrplot)</code></pre>
<pre><code>## Warning: package &#39;corrplot&#39; was built under R version 4.3.3</code></pre>
<pre><code>## corrplot 0.92 loaded</code></pre>
<pre class="r"><code>library(randomForest)</code></pre>
<pre><code>## Warning: package &#39;randomForest&#39; was built under R version 4.3.3</code></pre>
<pre><code>## randomForest 4.7-1.1
## Type rfNews() to see new features/changes/bug fixes.
## 
## Attaching package: &#39;randomForest&#39;
## 
## The following object is masked from &#39;package:psych&#39;:
## 
##     outlier
## 
## The following object is masked from &#39;package:dplyr&#39;:
## 
##     combine
## 
## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<pre class="r"><code>library(Hmisc)</code></pre>
<pre><code>## Warning: package &#39;Hmisc&#39; was built under R version 4.3.3</code></pre>
<pre><code>## 
## Attaching package: &#39;Hmisc&#39;
## 
## The following object is masked from &#39;package:e1071&#39;:
## 
##     impute
## 
## The following object is masked from &#39;package:psych&#39;:
## 
##     describe
## 
## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     src, summarize
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     format.pval, units</code></pre>
<pre class="r"><code>library(zoo)
library(forecast)</code></pre>
<pre><code>## Warning: package &#39;forecast&#39; was built under R version 4.3.3</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;quantmod&#39;:
##   method            from
##   as.zoo.data.frame zoo</code></pre>
<pre class="r"><code>library(tseries)</code></pre>
<pre><code>## Warning: package &#39;tseries&#39; was built under R version 4.3.3</code></pre>
<div id="importing-the-dataset" class="section level2">
<h2>Importing The Dataset</h2>
<pre class="r"><code>df &lt;- read.csv(&quot;C:/Users/Emeka/Downloads/WRFdata_May2018.csv&quot;)
nrow(df)</code></pre>
<pre><code>## [1] 5452</code></pre>
<pre class="r"><code># Selecting the rows that point to the location necessary for this analysis
new_df &lt;- df[c(1, 3423), ]

# Replacing a wrong column name with the right one
names(new_df)[names(new_df) == &#39;X.2225&#39;] &lt;- &#39;X31.05.2018.21.00&#39;</code></pre>
<pre class="r"><code># Deleting the Longitude and Latitude Columns
new_df &lt;- new_df[-c(1,2)]</code></pre>
<pre class="r"><code>extract_datetime &lt;- function(header) {
  match &lt;- str_extract(header, &quot;\\d{2}.\\d{2}.\\d{4}.\\d{2}.\\d{2}&quot;)
  return(ifelse(is.na(match), &quot;&quot;, match))
}</code></pre>
</div>
<div id="implementing-sapply" class="section level2">
<h2>Implementing sapply</h2>
<p>This function was then applied using the “sapply” function on all the
column names to extract all the datetimes.</p>
<pre class="r"><code>extracted_datetime &lt;- sapply(colnames(new_df), extract_datetime)</code></pre>
<p>The extracted datetime characters were then then stored in a separate
data frame. The resulting blank rows were deleted</p>
<pre class="r"><code># Creating a separate dataframe for the extracted datetime
datetime_df &lt;- data.frame(datetime = extracted_datetime)
datetime_df1 &lt;- data.frame(data = datetime_df)


# Handling the blank rows
datetime_df &lt;- datetime_df[!apply(is.na(datetime_df) | datetime_df == &quot;&quot;, 1, all), ]
datetime_df1 &lt;- data.frame(data = datetime_df)

head(datetime_df1)</code></pre>
<pre><code>##               data
## 1 01.05.2018.00.00
## 2 01.05.2018.03.00
## 3 01.05.2018.06.00
## 4 01.05.2018.09.00
## 5 01.05.2018.12.00
## 6 01.05.2018.15.00</code></pre>
<pre class="r"><code>#Creating a copy of our dataframe
newdf_copy &lt;- new_df

# Replacing the column headers with the header row
header_row_index &lt;- 1
colnames(newdf_copy) &lt;- unlist(newdf_copy[header_row_index, ])
newdf_copy &lt;- newdf_copy[-header_row_index, ] # Delete the header row</code></pre>
</div>
<div id="handling-missing-values" class="section level2">
<h2>Handling Missing Values</h2>
<pre class="r"><code># Handling the NA&#39;s in the column headers
num_repeats &lt;- ceiling(ncol(newdf_copy) / 10)
new_names &lt;- paste0(rep(c(&quot;TSK&quot;, &quot;PSFC&quot;, &quot;U10&quot;, &quot;V10&quot;, &quot;Q2&quot;, &quot;RAINC&quot;, &quot;RAINNC&quot;, &quot;SNOW&quot;, &quot;TSLB&quot;, &quot;SMOIS&quot;), times = num_repeats))
colnames(newdf_copy) &lt;- new_names</code></pre>
<p>The dataset was then split into smaller data frames of 10 columns
each. All these individual data frames were then stored as a list. This
list of separate data frames was then merged to form a singular data
frame consisting of 248 rows and 10 columns</p>
<pre class="r"><code>#Splitting the Dataframe into separate dataframes
split_dfs &lt;- split.default(newdf_copy, rep(1:(ncol(newdf_copy) %/% 10), each = 10))
View(split_dfs)
# Converting all column format to the numeric format
for (i in seq_along(split_dfs)) {
  split_dfs[[i]] &lt;- lapply(split_dfs[[i]], as.numeric)
}

# Merging the split dataframes
merged_df &lt;- bind_rows(split_dfs)
glimpse(merged_df)</code></pre>
<pre><code>## Rows: 248
## Columns: 10
## $ TSK    &lt;dbl&gt; 277.6, 276.3, 277.6, 287.4, 293.2, 287.4, 283.7, 281.7, 280.7, …
## $ PSFC   &lt;dbl&gt; 99325, 99313, 99300, 99255, 99163, 99071, 99018, 98863, 98694, …
## $ U10    &lt;dbl&gt; 3.3, 3.5, 2.0, 3.0, 4.1, 3.6, 1.9, 0.7, 0.2, 1.1, 1.6, 4.3, 4.5…
## $ V10    &lt;dbl&gt; -2.0, -0.9, 1.0, 3.2, 5.5, 5.4, 6.4, 6.5, 6.6, 8.9, 8.3, -0.9, …
## $ Q2     &lt;dbl&gt; 0.00377, 0.00354, 0.00380, NA, 0.00437, NA, 0.00521, 0.00492, 0…
## $ RAINC  &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, NA, 0.1, 0.1, 0.1,…
## $ RAINNC &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 4.1, 6.1, 6.1…
## $ SNOW   &lt;dbl&gt; 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ TSLB   &lt;dbl&gt; 278.9, 277.6, 277.3, 283.2, 289.4, 287.9, 284.8, 282.5, 281.1, …
## $ SMOIS  &lt;dbl&gt; 0.3123, 0.3103, NA, 0.3073, 0.3060, 0.3049, 0.3038, 0.3028, 0.3…</code></pre>
</div>
<div id="handling-the-missing-values-in-the-columns"
class="section level2">
<h2>Handling the Missing Values in the Columns</h2>
<p>To address the missing values in this merged dataset, a for loop was
created. The function of this loop was to fill the missing values with
the average of the top and bottom values of the column. This ensures a
fair and non-biased imputation method. The final data frame is then
merged with the extracted datetime data frame to get the final dataset
that would be used for analysis and modelling</p>
<pre class="r"><code># Function to fill the missing values with the average of the top and bottom values of the column
fill_na_with_avg &lt;- function(x) {
  for (i in 2:(length(x) - 1)) {
    if (is.na(x[i])) {
      x[i] &lt;- mean(c(x[i - 1], x[i + 1]), na.rm = TRUE)
    }
  } 
  return(x)
}

merged_df &lt;- apply(merged_df,2,fill_na_with_avg)</code></pre>
</div>
<div id="data-validation" class="section level2">
<h2>Data Validation</h2>
<p>Checking the integrity, accuracy, and consistency of data is a
crucial aspect of the data cleaning process, known as data validation.
The main aim of data validation is to identify and rectify errors,
anomalies, and inconsistencies in the dataset, which ultimately enhances
the overall reliability and quality of the data used for analysis or
modelling purposes. Data validation was carried out in the dataset, this
involved transforming the class of the numeric variables to numeric
format and the datetime column to “POSIXct” format.</p>
<pre class="r"><code># Joining the datetime dataframe with the merged dataframe
data_weather &lt;- cbind(merged_df, datetime_df1 )
glimpse(data_weather)</code></pre>
<pre><code>## Rows: 248
## Columns: 11
## $ TSK    &lt;dbl&gt; 277.6, 276.3, 277.6, 287.4, 293.2, 287.4, 283.7, 281.7, 280.7, …
## $ PSFC   &lt;dbl&gt; 99325, 99313, 99300, 99255, 99163, 99071, 99018, 98863, 98694, …
## $ U10    &lt;dbl&gt; 3.30, 3.50, 2.00, 3.00, 4.10, 3.60, 1.90, 0.70, 0.20, 1.10, 1.6…
## $ V10    &lt;dbl&gt; -2.0, -0.9, 1.0, 3.2, 5.5, 5.4, 6.4, 6.5, 6.6, 8.9, 8.3, -0.9, …
## $ Q2     &lt;dbl&gt; 0.003770, 0.003540, 0.003800, 0.004085, 0.004370, 0.004790, 0.0…
## $ RAINC  &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.05, 0.1…
## $ RAINNC &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 4.1, 6.1, 6.1…
## $ SNOW   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ TSLB   &lt;dbl&gt; 278.90, 277.60, 277.30, 283.20, 289.40, 287.90, 284.80, 282.50,…
## $ SMOIS  &lt;dbl&gt; 0.3123, 0.3103, 0.3088, 0.3073, 0.3060, 0.3049, 0.3038, 0.3028,…
## $ data   &lt;chr&gt; &quot;01.05.2018.00.00&quot;, &quot;01.05.2018.03.00&quot;, &quot;01.05.2018.06.00&quot;, &quot;01…</code></pre>
<pre class="r"><code># Changing the datetime column name with its appropriate name
data_weather$DATETIME &lt;- data_weather$data
data_weather &lt;- select(data_weather, -data)


# Convert the datetime column to POSIXct format
format_string &lt;- &quot;%d.%m.%Y.%H.%M&quot; 
data_weather$DATETIME&lt;- as.POSIXct(data_weather$DATETIME, format = format_string)


head(data_weather)</code></pre>
<pre><code>##     TSK  PSFC U10  V10       Q2 RAINC RAINNC SNOW  TSLB  SMOIS
## 1 277.6 99325 3.3 -2.0 0.003770     0      0    0 278.9 0.3123
## 2 276.3 99313 3.5 -0.9 0.003540     0      0    0 277.6 0.3103
## 3 277.6 99300 2.0  1.0 0.003800     0      0    0 277.3 0.3088
## 4 287.4 99255 3.0  3.2 0.004085     0      0    0 283.2 0.3073
## 5 293.2 99163 4.1  5.5 0.004370     0      0    0 289.4 0.3060
## 6 287.4 99071 3.6  5.4 0.004790     0      0    0 287.9 0.3049
##              DATETIME
## 1 2018-05-01 00:00:00
## 2 2018-05-01 03:00:00
## 3 2018-05-01 06:00:00
## 4 2018-05-01 09:00:00
## 5 2018-05-01 12:00:00
## 6 2018-05-01 15:00:00</code></pre>
<div id="calculating-wind-speed" class="section level3">
<h3>Calculating Wind Speed</h3>
<p>Since Wind Speed would be crucial for the analysis of Birmingham’s
weather, it was calculated from the X and Y component of wind available
in the dataset.</p>
<pre class="r"><code>data_weather$WIND_SPEED &lt;- round(sqrt(data_weather$U10^2 + data_weather$V10^2), 2)</code></pre>
</div>
</div>
<div id="exploratory-data-analysis" class="section level1">
<h1>Exploratory Data Analysis</h1>
<pre class="r"><code>str(data_weather)</code></pre>
<pre><code>## &#39;data.frame&#39;:    248 obs. of  12 variables:
##  $ TSK       : num  278 276 278 287 293 ...
##  $ PSFC      : num  99325 99313 99300 99255 99163 ...
##  $ U10       : num  3.3 3.5 2 3 4.1 3.6 1.9 0.7 0.2 1.1 ...
##  $ V10       : num  -2 -0.9 1 3.2 5.5 5.4 6.4 6.5 6.6 8.9 ...
##  $ Q2        : num  0.00377 0.00354 0.0038 0.00409 0.00437 ...
##  $ RAINC     : num  0 0 0 0 0 0 0 0 0 0.05 ...
##  $ RAINNC    : num  0 0 0 0 0 0 0 0 0.2 0.6 ...
##  $ SNOW      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TSLB      : num  279 278 277 283 289 ...
##  $ SMOIS     : num  0.312 0.31 0.309 0.307 0.306 ...
##  $ DATETIME  : POSIXct, format: &quot;2018-05-01 00:00:00&quot; &quot;2018-05-01 03:00:00&quot; ...
##  $ WIND_SPEED: num  3.86 3.61 2.24 4.39 6.86 6.49 6.68 6.54 6.6 8.97 ...</code></pre>
<p>The output above gives the structure of the dataset displaying the
format of all the variables</p>
<p>The code below gives out the summary statistics of the dataset.
Displaying the minimum, maximum, mean, median, 1st quartile and 3rd
quartile distribution of all the columns in the dataset</p>
<pre class="r"><code>summary(data_weather)</code></pre>
<pre><code>##       TSK             PSFC             U10               V10         
##  Min.   :276.3   Min.   : 98362   Min.   :-7.0000   Min.   :-5.3000  
##  1st Qu.:284.4   1st Qu.: 99846   1st Qu.:-2.2250   1st Qu.:-3.0250  
##  Median :287.8   Median :100294   Median :-0.4000   Median :-0.9000  
##  Mean   :289.4   Mean   :100221   Mean   :-0.4657   Mean   :-0.6476  
##  3rd Qu.:294.1   3rd Qu.:100644   3rd Qu.: 1.3000   3rd Qu.: 1.3000  
##  Max.   :305.6   Max.   :101330   Max.   : 5.7000   Max.   : 8.9000  
##        Q2               RAINC             RAINNC            SNOW  
##  Min.   :0.003470   Min.   : 0.0000   Min.   :0.0000   Min.   :0  
##  1st Qu.:0.005205   1st Qu.: 0.0000   1st Qu.:0.0000   1st Qu.:0  
##  Median :0.006725   Median : 0.0000   Median :0.0000   Median :0  
##  Mean   :0.006768   Mean   : 0.7387   Mean   :0.2952   Mean   :0  
##  3rd Qu.:0.007965   3rd Qu.: 0.0000   3rd Qu.:0.0000   3rd Qu.:0  
##  Max.   :0.011880   Max.   :29.1000   Max.   :6.1000   Max.   :0  
##       TSLB           SMOIS           DATETIME                     WIND_SPEED   
##  Min.   :277.3   Min.   :0.2896   Min.   :2018-05-01 00:00:00   Min.   :0.410  
##  1st Qu.:284.8   1st Qu.:0.2967   1st Qu.:2018-05-08 17:15:00   1st Qu.:2.090  
##  Median :287.8   Median :0.3024   Median :2018-05-16 10:30:00   Median :3.330  
##  Mean   :288.7   Mean   :0.3045   Mean   :2018-05-16 10:30:00   Mean   :3.450  
##  3rd Qu.:292.2   3rd Qu.:0.3098   3rd Qu.:2018-05-24 03:45:00   3rd Qu.:4.612  
##  Max.   :301.9   Max.   :0.3720   Max.   :2018-05-31 21:00:00   Max.   :8.970</code></pre>
<pre class="r"><code>head(data_weather) #Displays first 6 rows</code></pre>
<pre><code>##     TSK  PSFC U10  V10       Q2 RAINC RAINNC SNOW  TSLB  SMOIS
## 1 277.6 99325 3.3 -2.0 0.003770     0      0    0 278.9 0.3123
## 2 276.3 99313 3.5 -0.9 0.003540     0      0    0 277.6 0.3103
## 3 277.6 99300 2.0  1.0 0.003800     0      0    0 277.3 0.3088
## 4 287.4 99255 3.0  3.2 0.004085     0      0    0 283.2 0.3073
## 5 293.2 99163 4.1  5.5 0.004370     0      0    0 289.4 0.3060
## 6 287.4 99071 3.6  5.4 0.004790     0      0    0 287.9 0.3049
##              DATETIME WIND_SPEED
## 1 2018-05-01 00:00:00       3.86
## 2 2018-05-01 03:00:00       3.61
## 3 2018-05-01 06:00:00       2.24
## 4 2018-05-01 09:00:00       4.39
## 5 2018-05-01 12:00:00       6.86
## 6 2018-05-01 15:00:00       6.49</code></pre>
<p>This gives a brief description of the dataset showing values like the
standard deviation, etc</p>
<pre class="r"><code>describe(data_weather)</code></pre>
<pre><code>## data_weather 
## 
##  12  Variables      248  Observations
## --------------------------------------------------------------------------------
## TSK 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      156        1    289.4    7.568    281.0    281.6 
##      .25      .50      .75      .90      .95 
##    284.3    287.8    294.2    299.7    302.2 
## 
## lowest : 276.3 277.6 278   279.1 279.3, highest: 303.9 304.2 304.4 305   305.6
## --------------------------------------------------------------------------------
## PSFC 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      235        1   100221    655.5    99219    99410 
##      .25      .50      .75      .90      .95 
##    99846   100294   100644   100889   101094 
## 
## lowest :  98362  98490  98497  98694  98779, highest: 101248 101268 101272 101290 101330
## --------------------------------------------------------------------------------
## U10 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      101        1  -0.4657     2.88   -4.900   -3.930 
##      .25      .50      .75      .90      .95 
##   -2.225   -0.400    1.300    2.800    3.900 
## 
## lowest : -7   -6.8 -5.8 -5.5 -5.2, highest: 4.6  4.7  4.9  5    5.7 
## --------------------------------------------------------------------------------
## V10 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0       99        1  -0.6476    3.157   -4.300   -4.000 
##      .25      .50      .75      .90      .95 
##   -3.025   -0.900    1.300    2.700    3.925 
## 
## lowest : -5.3 -5   -4.8 -4.7 -4.5, highest: 6.5  6.6  6.7  8.3  8.9 
## --------------------------------------------------------------------------------
## Q2 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      216        1 0.006768 0.002099 0.004094 0.004431 
##      .25      .50      .75      .90      .95 
## 0.005205 0.006725 0.007965 0.009179 0.010009 
## 
## lowest : 0.00347 0.00354 0.00361 0.00371 0.00372
## highest: 0.0115  0.01161 0.01168 0.0117  0.01188
## --------------------------------------------------------------------------------
## RAINC 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0       23    0.451   0.7387    1.379      0.0      0.0 
##      .25      .50      .75      .90      .95 
##      0.0      0.0      0.0      1.9      3.7 
## 
## lowest : 0    0.05 0.1  0.2  0.5 , highest: 7.2  7.9  16.2 28.5 29.1
## --------------------------------------------------------------------------------
## RAINNC 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0       12    0.557   0.2952   0.5388     0.00     0.00 
##      .25      .50      .75      .90      .95 
##     0.00     0.00     0.00     0.53     2.33 
##                                                                             
## Value        0.0   0.1   0.2   0.3   0.4   0.5   0.6   1.0   2.2   2.4   4.1
## Frequency    189    13     4     3     6     8     2     9     1     7     1
## Proportion 0.762 0.052 0.016 0.012 0.024 0.032 0.008 0.036 0.004 0.028 0.004
##                 
## Value        6.1
## Frequency      5
## Proportion 0.020
## 
## For the frequency table, variable is rounded to the nearest 0
## --------------------------------------------------------------------------------
## SNOW 
##        n  missing distinct     Info     Mean      Gmd 
##      248        0        1        0        0        0 
##               
## Value        0
## Frequency  248
## Proportion   1
## --------------------------------------------------------------------------------
## TSLB 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      139        1    288.7    6.129    281.2    282.3 
##      .25      .50      .75      .90      .95 
##    284.8    287.8    292.2    297.2    298.5 
## 
## lowest : 277.3 277.6 278.9 279.1 280.1, highest: 299.6 299.7 299.9 300.1 301.9
## --------------------------------------------------------------------------------
## SMOIS 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      178        1   0.3045  0.01113   0.2922   0.2937 
##      .25      .50      .75      .90      .95 
##   0.2967   0.3024   0.3098   0.3164   0.3224 
## 
## lowest : 0.2896 0.2902 0.2907 0.2911 0.2913, highest: 0.3336 0.3409 0.3477 0.3696 0.372 
## --------------------------------------------------------------------------------
## DATETIME 
##                   n             missing            distinct                Info 
##                 248                   0                 248                   1 
##                Mean                 Gmd                 .05                 .10 
## 2018-05-16 10:30:00              896400 2018-05-02 13:03:00 2018-05-04 02:06:00 
##                 .25                 .50                 .75                 .90 
## 2018-05-08 17:15:00 2018-05-16 10:30:00 2018-05-24 03:45:00 2018-05-28 18:54:00 
##                 .95 
## 2018-05-30 07:57:00 
## 
## lowest : 2018-05-01 00:00:00 2018-05-01 03:00:00 2018-05-01 06:00:00 2018-05-01 09:00:00 2018-05-01 12:00:00
## highest: 2018-05-31 09:00:00 2018-05-31 12:00:00 2018-05-31 15:00:00 2018-05-31 18:00:00 2018-05-31 21:00:00
## --------------------------------------------------------------------------------
## WIND_SPEED 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      248        0      196        1     3.45    1.968   0.9035   1.3000 
##      .25      .50      .75      .90      .95 
##   2.0900   3.3300   4.6125   5.7560   6.5225 
## 
## lowest : 0.41 0.5  0.54 0.6  0.64, highest: 7.16 7.84 8.22 8.45 8.97
## --------------------------------------------------------------------------------</code></pre>
<pre class="r"><code># Checking for duplicate values
duplicated(data_weather)</code></pre>
<pre><code>##   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [169] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [193] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [205] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [217] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [229] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [241] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</code></pre>
<p>The output above means that there are no duplicated values in the
dataset</p>
<pre class="r"><code>pairs(data_weather)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>The output of the image above shows a pairplot. A pairplot is a type
of visualization in data analysis that displays pairwise relationships
between variables in a dataset. It is typically used to explore the
relationships between multiple numerical variables and identify patterns
or correlations between them</p>
<pre class="r"><code>ggplot(data_weather, aes(x = TSK)) +
  geom_histogram(binwidth = 0.5, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Histogram of Surface Temperature&quot;, x = &quot;Surface Temperature&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code># Checking the skewness and Kurtosis of TSK
print(paste(&quot;The value of the skewness is: &quot;, skewness(data_weather$TSK)))</code></pre>
<pre><code>## [1] &quot;The value of the skewness is:  0.533322159485486&quot;</code></pre>
<pre class="r"><code>kurtosis_TSK&lt;- kurtosis(data_weather$TSK, na.rm = TRUE)
print(paste(&quot;The value of the kurtosis is:&quot;, kurtosis_TSK))</code></pre>
<pre><code>## [1] &quot;The value of the kurtosis is: -0.61823558112505&quot;</code></pre>
<p>From the result above it can be seen that the distribution is
moderately right skewed and the kurtosis is platykurtic.</p>
<pre class="r"><code>ggplot(data_weather, aes(x = PSFC)) +
  geom_histogram(binwidth = 30, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Histogram of Surface Pressure&quot;, x = &quot;Surface Pressure&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code># Checking the skewness and Kurtosis of PSFC
print(paste(&quot;The value of the skewness is: &quot;, skewness(data_weather$PSFC)))</code></pre>
<pre><code>## [1] &quot;The value of the skewness is:  -0.541823171496961&quot;</code></pre>
<pre class="r"><code>kurtosis_PSFC&lt;- kurtosis(data_weather$PSFC, na.rm = TRUE)
print(paste(&quot;The value of the kurtosis is:&quot;, kurtosis_PSFC))</code></pre>
<pre><code>## [1] &quot;The value of the kurtosis is: 0.0660054967303383&quot;</code></pre>
<p>From the distribution of the surface pressure, it can be seen that it
is left skewed and it has a low kurtosis.</p>
<pre class="r"><code>ggplot(data_weather, aes(x = WIND_SPEED)) +
  geom_histogram(binwidth = 0.5, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Histogram of Wind Speed&quot;, x = &quot;Wind Speed&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code># Checking the skewness and Kurtosis of Wind Speed
print(paste(&quot;The value of the skewness is: &quot;, skewness(data_weather$WIND_SPEED)))</code></pre>
<pre><code>## [1] &quot;The value of the skewness is:  0.435459611882918&quot;</code></pre>
<pre class="r"><code>kurtosis_WINDSPEED&lt;- kurtosis(data_weather$WIND_SPEED, na.rm = TRUE)
print(paste(&quot;The value of the kurtosis is:&quot;, kurtosis_WINDSPEED))</code></pre>
<pre><code>## [1] &quot;The value of the kurtosis is: -0.260091385888312&quot;</code></pre>
<p>From the above, the distribution is right skewed with a low
kurtosis</p>
<pre class="r"><code>ggplot(data_weather, aes(x = RAINNC)) +
  geom_histogram(binwidth = 0.5, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Non-convective Rain&quot;, x = &quot;Non-Convective Rain&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code># Checking the skewness and Kurtosis of RAINNC
print(paste(&quot;The value of the skewness is: &quot;, skewness(data_weather$RAINNC)))</code></pre>
<pre><code>## [1] &quot;The value of the skewness is:  4.65614679109489&quot;</code></pre>
<pre class="r"><code>kurtosis_RAINNC&lt;- kurtosis(data_weather$RAINNC, na.rm = TRUE)
print(paste(&quot;The value of the kurtosis is:&quot;, kurtosis_RAINNC))</code></pre>
<pre><code>## [1] &quot;The value of the kurtosis is: 22.8750348574582&quot;</code></pre>
<p>From the distribution, it can be seen that it is highly right skewed
with a very high kurtosis.</p>
<pre class="r"><code>ggplot(data_weather, aes(x = TSLB)) +
  geom_histogram(binwidth = 1, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Soil Temperature&quot;, x = &quot;Soil Temperature&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<pre class="r"><code># Checking the skewness and Kurtosis of TSLB
print(paste(&quot;The value of the skewness is: &quot;, skewness(data_weather$TSLB)))</code></pre>
<pre><code>## [1] &quot;The value of the skewness is:  0.431540397937841&quot;</code></pre>
<pre class="r"><code>kurtosis_TSLB&lt;- kurtosis(data_weather$TSLB, na.rm = TRUE)
print(paste(&quot;The value of the kurtosis is:&quot;, kurtosis_TSLB))</code></pre>
<pre><code>## [1] &quot;The value of the kurtosis is: -0.694589843195905&quot;</code></pre>
<p>From the distribution above, it shows it is moderately right skewed
with low kurtosis</p>
<pre class="r"><code>ggplot(data_weather, aes(x = Q2)) +
  geom_histogram(binwidth = 0.1, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;2-meter specific humidity&quot;, x = &quot;2-meter specific humidity&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<pre class="r"><code># Checking the skewness and Kurtosis of TSK
print(paste(&quot;The value of the skewness is: &quot;, skewness(data_weather$Q2)))</code></pre>
<pre><code>## [1] &quot;The value of the skewness is:  0.427756009195485&quot;</code></pre>
<pre class="r"><code>kurtosis_Q2&lt;- kurtosis(data_weather$Q2, na.rm = TRUE)
print(paste(&quot;The value of the kurtosis is:&quot;, kurtosis_Q2))</code></pre>
<pre><code>## [1] &quot;The value of the kurtosis is: -0.250490989692109&quot;</code></pre>
<p>Here, although the distribution can not be visually recognised, from
the skewness and kurtosis calculations, we can say that the distribution
is moderately right skewed with a relatively low kurtosis</p>
<pre class="r"><code>#Boxplot for Skin temperature
ggplot(data_weather, aes(y = TSK)) +
  geom_boxplot(outlier.color = &#39;red&#39;) +
  labs(title = &quot;Skin Temperature&quot;) </code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre class="r"><code>#Boxplot for surface pressure

ggplot(data_weather, aes(y = PSFC)) +
  geom_boxplot(outlier.color = &quot;red&quot;) +
  labs(title = &quot;Surface Pressure&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<pre class="r"><code>#Print the outliers
Outlier_Psfc &lt;- data_weather$PSFC
z_scores &lt;- scale(Outlier_Psfc)
threshold &lt;- 2
outliers &lt;- Outlier_Psfc[abs(z_scores) &gt; threshold]
print(outliers)</code></pre>
<pre><code>## [1] 99018 98863 98694 98497 98362 98490 98779 99014</code></pre>
<pre class="r"><code>#Boxplot for 2-meter specific humidity
ggplot(data_weather, aes(y = Q2)) +
  geom_boxplot(outlier.colour = &quot;red&quot;) +
  labs(title = &quot;2-meter specific humidity&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data_weather, aes(y = WIND_SPEED)) +
  geom_boxplot(outlier.colour = &quot;red&quot;) +
  labs(title = &quot;Wind Speed&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<pre class="r"><code>#Print the outliers
Outlier_Wind &lt;- data_weather$WIND_SPEED
z_scores &lt;- scale(Outlier_Wind)
threshold &lt;- 2
outliers &lt;- Outlier_Wind[abs(z_scores) &gt; threshold]
print(outliers)</code></pre>
<pre><code>## [1] 8.97 8.45 8.22 7.84 7.16</code></pre>
<pre class="r"><code>ggplot(data_weather, aes(y = TSLB)) +
  geom_boxplot(outlier.colour = &quot;red&quot;) +
  labs(title = &quot;Soil Temperature&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Upon careful inspection of the outliers and comparing it to our
available dataset, it was deduced that the outliers are valid data
points. Outliers don’t necessarily mean errors. In some cases, they
might represent genuine but rare events or observations within the data
set.</p>
<div id="lineplots" class="section level2">
<h2>LinePlots</h2>
<p>Line plots are a basic tool for visualising data trends across a
continuous variable. By displaying how a specific variable changes over
time or different categories, line plots provide a clear and concise
method for communicating complex information effectively.</p>
<pre class="r"><code>#Lineplot to see the trend of  the Wind Speed variable over 30 days
ggplot(data_weather, aes(x = DATETIME, y = WIND_SPEED)) +
  geom_line(color = &#39;blue&#39;, linewidth = 1.0) +
  labs(x = &quot;Datetime&quot;, y = &quot;Wind Speed&quot;) +
  ggtitle(&quot;Trend of Wind Speed Over Time&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>#Lineplot to see the trend of  Surface temperature variable over 30 days
ggplot(data_weather, aes(x = DATETIME, y = TSK)) +
  geom_line(color = &#39;blue&#39;, linewidth = 1.0) +
  labs(x = &quot;Datetime&quot;, y = &quot;Surface temperature&quot;) +
  ggtitle(&quot;Trend of Surface Temperature Over Time&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<pre class="r"><code>#Lineplot to see the trend of  the Surface pressure variable over 30 days
ggplot(data_weather, aes(x = DATETIME, y = PSFC)) +
  geom_line(color = &#39;blue&#39;, linewidth = 1.0) +
  labs(x = &quot;Datetime&quot;, y = &quot;Surface pressure&quot;) +
  ggtitle(&quot;Trend of Surface pressure Over Time&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<pre class="r"><code>#Lineplot to see the trend of  the Non-convective rain variable over 30 days
ggplot(data_weather, aes(x = DATETIME, y = RAINNC)) +
  geom_line(color = &#39;blue&#39;, linewidth = 1.0) +
  labs(x = &quot;Datetime&quot;, y = &quot;Non-convective rain&quot;) +
  ggtitle(&quot;Trend of Non-convective rain Over Time&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<pre class="r"><code>#Lineplot to see the trend of  2-meter specific humidity variable over 30 days
ggplot(data_weather, aes(x = DATETIME, y = Q2)) +
  geom_line(color = &#39;blue&#39;, linewidth = 1.0) +
  labs(x = &quot;Datetime&quot;, y = &quot;2-meter specific humidity&quot;) +
  ggtitle(&quot;Trend of 2-meter specific humidity Over Time&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
</div>
</div>
<div id="statistical-analysis" class="section level1">
<h1>Statistical Analysis</h1>
<div id="research-question-1-univariate-analysis"
class="section level2">
<h2>Research Question 1: Univariate analysis</h2>
<p>What is the average distribution of surface temperature across the
dataset?</p>
<p>Finding the distribution of the surface temperature across a
thirty-day time period helps to determine a baseline.</p>
<p>1a.) Null Hypothesis (H0) : There is no significant difference in
surface temperature</p>
<p>1b.) Alternative Hypothesis (H1) : Surface temperature significantly
differs from the mean temperature.</p>
<pre class="r"><code>#Showing the summary statistics
summary(data_weather$TSK)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   276.3   284.4   287.8   289.4   294.1   305.6</code></pre>
<p>The result above shows the summary description of the surface
temperature variable. It shows that the mean surface temperature across
the 30 day time period was 289.4</p>
<pre class="r"><code>#Plotting the Histogram
ggplot(data_weather, aes(x = TSK)) +
  geom_histogram(binwidth = 0.5, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Histogram of Surface Temperature&quot;, x = &quot;Surface Temperature&quot;, y = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>The histogram shows the visual distribution of the Surface
temperature variable. It shows the peak value of the surface at around
the 289 mark. The distribution is right skewed.</p>
<div id="hypothesis-test" class="section level3">
<h3>Hypothesis Test</h3>
<pre class="r"><code>#Getting a reference value
reference_value &lt;- mean(data_weather$TSK)

#Performing one-sample t-test
t_testResult &lt;- t.test(data_weather$TSK, mu = reference_value)
print(t_testResult)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  data_weather$TSK
## t = 0, df = 247, p-value = 1
## alternative hypothesis: true mean is not equal to 289.4167
## 95 percent confidence interval:
##  288.5794 290.2540
## sample estimates:
## mean of x 
##  289.4167</code></pre>
<p>The result above shows a p-value that is equal to 1. Since it is
greater than 0.05, this indicates that there is no evidence to reject
the null hypothesis. In other words, the test does not find any
significant difference or effect. The null hypothesis being that there
is no significant difference in the mean surface temperature. We then
accept the null hypothesis.</p>
<pre class="r"><code>#Test for Normality
shapiro.test(data_weather$TSK)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  data_weather$TSK
## W = 0.95543, p-value = 6.373e-07</code></pre>
<p>From the above, a p-value less than 0.05 suggests that we can
confidently reject the null hypothesis. It means there’s no evidence to
suggest the data deviates from normality. In this case, the data shows a
non-normal distribution.</p>
</div>
</div>
<div id="research-question-2-bivariate-analysis" class="section level2">
<h2>Research Question 2 Bivariate Analysis</h2>
<p>How does Wind Speed have an influence on the surface pressure?</p>
<p>2a.) Null Hypothesis (H0): There is no relationship between wind
speed and surface pressure.</p>
<p>2b.) Alternative Hypothesis (H1): There is a relationship between
wind speed and surface pressure.</p>
<p>The two variables needed are Wind Speed and Surface Pressure</p>
<pre class="r"><code>#First a scatterplot to show the relationship
ggplot(data_weather, aes(x = WIND_SPEED, y = PSFC)) +
  geom_point(alpha = 5) +
  labs(x = &quot;Wind Speed&quot;, y = &quot;PSFC&quot;) +
  ggtitle(&quot;Scatterplot of Wind Speed vs Surface Pressure&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>To determine the correlation coefficient that would be used to check
the relationship, the distribution of the two variables have to be
checked to determine whether the Pearson, Spearman or Kendall
correlation function would be used. Although they perform similar tasks
they have differing assumptions.</p>
<p>When analyzing the relationship between two variables, Pearson
correlation is best suited for assessing linear relationships between
continuous variables that follow a normal distribution. On the other
hand, Spearman correlation is more appropriate for assessing monotonic
relationships, especially when the relationship is nonlinear or the data
are not normally distributed.</p>
<pre class="r"><code>#Test for normality for Wind Speed
shapiro.test(data_weather$WIND_SPEED)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  data_weather$WIND_SPEED
## W = 0.97676, p-value = 0.000436</code></pre>
<pre class="r"><code>#Test for normality for Surface Pressure
shapiro.test(data_weather$PSFC)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  data_weather$PSFC
## W = 0.97703, p-value = 0.0004799</code></pre>
<p>From the output above the p-value from both normality tests is seen
to be less than 0.05. This shows that the distribution is not normally
distributed. This then eliminates the need for pearson correlation
coefficient. A non parametric test called “Spearman” correlation would
be used.</p>
<pre class="r"><code>#Spearman correlation
cor(data_weather$WIND_SPEED, data_weather$PSFC, method = &quot;spearman&quot;)</code></pre>
<pre><code>## [1] -0.2106213</code></pre>
<pre class="r"><code>#Spearman correlation
rcorr(data_weather$WIND_SPEED, data_weather$PSFC, type = &#39;spearman&#39;)</code></pre>
<pre><code>##       x     y
## x  1.00 -0.21
## y -0.21  1.00
## 
## n= 248 
## 
## 
## P
##   x     y    
## x       8e-04
## y 8e-04</code></pre>
<p>From the result of the correlation tests above, it shows a weak
negative correlation between the two variables.</p>
<pre class="r"><code>#Spearman correlation using corr.test
cor.test(data_weather$WIND_SPEED, data_weather$PSFC, method = &#39;spearman&#39;)</code></pre>
<pre><code>## Warning in cor.test.default(data_weather$WIND_SPEED, data_weather$PSFC, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  data_weather$WIND_SPEED and data_weather$PSFC
## S = 3077549, p-value = 0.000845
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.2106213</code></pre>
<p>The p-value from this test is less than 0.05. This indicates that the
null hypothesis, which states that there is no correlation between the
two variables, can be rejected at a confidence level of 95%. Therefore,
it can be concluded that there exists a statistically significant
association between the two variables.</p>
</div>
<div id="research-question-3-multivariate-analysis"
class="section level2">
<h2>Research Question 3 Multivariate Analysis</h2>
<p>How do skin temperature, surface pressure and specific humidity
collectively influence convective rainfall and what is the nature of
their combined effects? Is there evidence of collaborative or opposing
relationships among these factors?</p>
<p>3a.) Null Hypothesis: There is no significant relationship between
the combined effects of skin temperature, surface pressure and specific
humidity on convective rainfall.</p>
<p>3b.) Alternative Hypothesis: There is a significant relationship
between the combined effects of skin temperature, surface pressure and
specific humidity on convective rainfall</p>
<pre class="r"><code>#Plotting a pairwise scatterplot to show relationship between the variables
pairs(data_weather[, c(&quot;TSK&quot;, &quot;PSFC&quot;, &quot;Q2&quot;, &quot;RAINC&quot;)])</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p>The plot above shows the pair relationship between each variable
using a scatter plot.</p>
<pre class="r"><code>#Using a multiple regression model
Multi_model &lt;- lm(RAINC ~ TSK + PSFC + Q2, data = data_weather)
summary(Multi_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = RAINC ~ TSK + PSFC + Q2, data = data_weather)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3630 -1.0927 -0.3981  0.3783 25.5420 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.631e+01  3.212e+01   1.442    0.151    
## TSK         -8.112e-03  2.918e-02  -0.278    0.781    
## PSFC        -4.691e-04  3.157e-04  -1.486    0.139    
## Q2           5.605e+02  1.053e+02   5.326 2.28e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.886 on 244 degrees of freedom
## Multiple R-squared:  0.1188, Adjusted R-squared:  0.108 
## F-statistic: 10.96 on 3 and 244 DF,  p-value: 8.841e-07</code></pre>
<p>From the result of the regression test,</p>
<p>1.) A positive coefficient for Q2 suggests a positive relationship
with Rainc (higher humidity leads to higher rain).</p>
<p>2.) A negative coefficient for PSFC and TSK indicates a negative
relationship (higher pressure and higher temperature leads to lower
rain).</p>
<p>But overall, the p-value is seen to be less than 0.05. Therefore, the
null hypothesis is rejected. This then signifies that there is a
significant relationship between the combined factors.</p>
<pre class="r"><code># Heatmap for Multivariate analysis
correlation_matrix &lt;- cor(data_weather[c(&quot;TSK&quot;,&quot;PSFC&quot;, &quot;Q2&quot;,&quot;RAINC&quot;)])
corrplot(correlation_matrix, method = &quot;color&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<p>The heat map shows the positive or negative correlation between each
variable</p>
<div id="visualisations" class="section level3">
<h3>Visualisations</h3>
<pre class="r"><code>plot(Multi_model)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-57-1.png" width="672" /><img src="index_files/figure-html/unnamed-chunk-57-2.png" width="672" /><img src="index_files/figure-html/unnamed-chunk-57-3.png" width="672" /><img src="index_files/figure-html/unnamed-chunk-57-4.png" width="672" /></p>
<p>1.) Residuals vs Fitted: This plot verifys the assumptions of
linearity. When the residuals exhibit an equal spread around the
horizontal line without noticeable patterns, it strongly implies the
presence of a linear relationship.</p>
<p>2.) Normal Q-Q: This plot verifys the assumption of normality
regarding residuals. If the majority of residuals closely adhere to the
straight dashed line, then the assumption is satisfied.</p>
<p>3.) Scale-Location: This plot is utilized to examine the
homoscedasticity of residuals, ensuring that their variance remains
constant. When the residuals are evenly distributed along the straight
line, it confirms homoscedasticity. It suggests that the model meets an
important assumption of linear regression and doesn’t exhibit a
systematic bias in its residuals.</p>
<p>Residuals vs Leverage: This visualization is employed to detect any
influential values present within the dataset.</p>
</div>
<div id="non-parametric-tests" class="section level3">
<h3>Non-Parametric Tests</h3>
<p>Generalized Additive Models (GAMs): GAMs allow for non-linear
relationships between predictor variables and the outcome variable by
using flexible spline functions. This can capture non-linear patterns in
the data more effectively than traditional linear regression models.</p>
<pre class="r"><code>library(gam)</code></pre>
<pre><code>## Warning: package &#39;gam&#39; was built under R version 4.3.3</code></pre>
<pre><code>## Loading required package: splines</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Warning: package &#39;foreach&#39; was built under R version 4.3.3</code></pre>
<pre><code>## 
## Attaching package: &#39;foreach&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:purrr&#39;:
## 
##     accumulate, when</code></pre>
<pre><code>## Loaded gam 1.22-3</code></pre>
<pre class="r"><code>model_gam &lt;- gam(RAINC ~ s(TSK) + s(PSFC) + s(Q2), data = data_weather)

# Summary of the GAM
summary(model_gam)</code></pre>
<pre><code>## 
## Call: gam(formula = RAINC ~ s(TSK) + s(PSFC) + s(Q2), data = data_weather)
## Deviance Residuals:
##      Min       1Q   Median       3Q      Max 
## -9.41901 -0.66130 -0.28397  0.09421 18.13149 
## 
## (Dispersion Parameter for gaussian family taken to be 5.8639)
## 
##     Null Deviance: 2306.743 on 247 degrees of freedom
## Residual Deviance: 1378.013 on 234.9997 degrees of freedom
## AIC: 1157.107 
## 
## Number of Local Scoring Iterations: NA 
## 
## Anova for Parametric Effects
##            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## s(TSK)      1    2.75   2.752  0.4693    0.4940    
## s(PSFC)     1    3.05   3.051  0.5204    0.4714    
## s(Q2)       1  219.10 219.101 37.3643 4.044e-09 ***
## Residuals 235 1378.01   5.864                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Anova for Nonparametric Effects
##             Npar Df Npar F   Pr(F)    
## (Intercept)                           
## s(TSK)            3  2.185 0.09048 .  
## s(PSFC)           3  0.936 0.42393    
## s(Q2)             3 34.466 &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Polynomial regression is a statistical method employed to depict the
connection between a dependent variable and one or more independent
variables. In contrast to linear regression, which presumes a linear
relationship between variables, polynomial regression accommodates
curved relationships by applying a polynomial equation to the
dataset.</p>
<pre class="r"><code>#Polynomial Regression Model
model_polynomial &lt;- lm(RAINC ~ poly(TSK, 2) + poly(PSFC, 2) + poly(Q2, 2), data = data_weather)

# Summary of the polynomial regression model
summary(model_polynomial)</code></pre>
<pre><code>## 
## Call:
## lm(formula = RAINC ~ poly(TSK, 2) + poly(PSFC, 2) + poly(Q2, 
##     2), data = data_weather)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9876 -0.8250 -0.0815  0.3237 20.3626 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      0.7387     0.1661   4.448 1.32e-05 ***
## poly(TSK, 2)1   -4.2381     2.8527  -1.486   0.1387    
## poly(TSK, 2)2   -5.1855     2.6739  -1.939   0.0536 .  
## poly(PSFC, 2)1  -0.6023     2.6737  -0.225   0.8220    
## poly(PSFC, 2)2  -1.5318     2.8413  -0.539   0.5903    
## poly(Q2, 2)1    16.1817     2.9212   5.539 7.93e-08 ***
## poly(Q2, 2)2    20.0196     2.7160   7.371 2.70e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.615 on 241 degrees of freedom
## Multiple R-squared:  0.2854, Adjusted R-squared:  0.2676 
## F-statistic: 16.04 on 6 and 241 DF,  p-value: 1.632e-15</code></pre>
<p>From the output of the non parametric tests carried out on the the
variables, we come to the same conclusion that the p-value for the
2-meter specific humidity (Q2) indicates a very high statistical
significance.</p>
</div>
</div>
</div>
<div id="machine-learning" class="section level1">
<h1>Machine Learning</h1>
<div id="research-question-4" class="section level2">
<h2>Research Question 4</h2>
<p>Can a machine learning model be used to predict wind based on other
weather variables such as wind speed, soil moisture, soil temperature
and can future wind speed valued be determined?</p>
<p>Firstly we have to determine which features to select. By examining
the correlation matrix and heatmap, we can identify pairs of variables
that are strongly correlated with each other.</p>
<pre class="r"><code>#Using a correlation heatmap to choose our features
correlation_matrix &lt;- cor(data_weather[c(&quot;TSK&quot;,&quot;PSFC&quot;, &quot;Q2&quot;,&quot;RAINC&quot;, &quot;RAINNC&quot;, &quot;WIND_SPEED&quot;,&quot;TSLB&quot;, &quot;SMOIS&quot;)])
corrplot(correlation_matrix, method = &quot;color&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<pre class="r"><code>print(correlation_matrix)</code></pre>
<pre><code>##                    TSK        PSFC          Q2       RAINC      RAINNC
## TSK         1.00000000  0.07258824  0.33452704  0.08934593 -0.04836348
## PSFC        0.07258824  1.00000000  0.01777472 -0.08478108 -0.37261282
## Q2          0.33452704  0.01777472  1.00000000  0.33209435 -0.19238844
## RAINC       0.08934593 -0.08478108  0.33209435  1.00000000 -0.02627175
## RAINNC     -0.04836348 -0.37261282 -0.19238844 -0.02627175  1.00000000
## WIND_SPEED  0.03081705 -0.28001601  0.03490304 -0.08217076  0.21013556
## TSLB        0.95271391  0.07388285  0.39350572  0.13366760 -0.06648146
## SMOIS      -0.04881301 -0.23655377  0.43582011  0.63234399  0.03751657
##             WIND_SPEED        TSLB       SMOIS
## TSK         0.03081705  0.95271391 -0.04881301
## PSFC       -0.28001601  0.07388285 -0.23655377
## Q2          0.03490304  0.39350572  0.43582011
## RAINC      -0.08217076  0.13366760  0.63234399
## RAINNC      0.21013556 -0.06648146  0.03751657
## WIND_SPEED  1.00000000  0.08881935  0.05194064
## TSLB        0.08881935  1.00000000 -0.03941878
## SMOIS       0.05194064 -0.03941878  1.00000000</code></pre>
<p>From the result above, positive correlations are displayed in the
blue color gradient, while negative correlations are displayed in brown.
The stronger the correlation, the darker the color. It can be deduced
that the “PSF” and “RAINC” variables gave a negative correlation.
Therefore they would not be chosen as part of our features for
prediction</p>
<pre class="r"><code>#Firstly we check whether linear regression would be suitable for this scenario
data_sub &lt;- data_weather[c(&quot;TSK&quot;, &quot;Q2&quot;, &quot;RAINNC&quot;, &quot;WIND_SPEED&quot;,&quot;TSLB&quot;, &quot;SMOIS&quot;)]

glimpse(data_sub)</code></pre>
<pre><code>## Rows: 248
## Columns: 6
## $ TSK        &lt;dbl&gt; 277.6, 276.3, 277.6, 287.4, 293.2, 287.4, 283.7, 281.7, 280…
## $ Q2         &lt;dbl&gt; 0.003770, 0.003540, 0.003800, 0.004085, 0.004370, 0.004790,…
## $ RAINNC     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 4.1, 6.1,…
## $ WIND_SPEED &lt;dbl&gt; 3.86, 3.61, 2.24, 4.39, 6.86, 6.49, 6.68, 6.54, 6.60, 8.97,…
## $ TSLB       &lt;dbl&gt; 278.90, 277.60, 277.30, 283.20, 289.40, 287.90, 284.80, 282…
## $ SMOIS      &lt;dbl&gt; 0.3123, 0.3103, 0.3088, 0.3073, 0.3060, 0.3049, 0.3038, 0.3…</code></pre>
<p>This is an extraction of the variables that would be used to build
out the machine learning models. PSFC and RAINC were omitted as they
gave a negative correlation.</p>
<pre class="r"><code>#Define the model
Model_Wind &lt;- WIND_SPEED ~ TSK + Q2+ RAINNC + TSLB + SMOIS

#Fitting the model
Linear_Wind &lt;- lm(Model_Wind, data = data_sub)

#Performing rainbow test
rainbowTest &lt;- raintest(Linear_Wind)

#Checking the p-value
rainbowTest$p.value</code></pre>
<pre><code>## [1] 0.008197042</code></pre>
<p>From the above the p-value is less than 0.05, this suggests the
linear model does not capture the entire relationship, therefore we
would be exploring other non-linear models.</p>
<div id="support-vector-regression" class="section level3">
<h3>Support Vector Regression</h3>
<pre class="r"><code>glimpse(data_sub)</code></pre>
<pre><code>## Rows: 248
## Columns: 6
## $ TSK        &lt;dbl&gt; 277.6, 276.3, 277.6, 287.4, 293.2, 287.4, 283.7, 281.7, 280…
## $ Q2         &lt;dbl&gt; 0.003770, 0.003540, 0.003800, 0.004085, 0.004370, 0.004790,…
## $ RAINNC     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 4.1, 6.1,…
## $ WIND_SPEED &lt;dbl&gt; 3.86, 3.61, 2.24, 4.39, 6.86, 6.49, 6.68, 6.54, 6.60, 8.97,…
## $ TSLB       &lt;dbl&gt; 278.90, 277.60, 277.30, 283.20, 289.40, 287.90, 284.80, 282…
## $ SMOIS      &lt;dbl&gt; 0.3123, 0.3103, 0.3088, 0.3073, 0.3060, 0.3049, 0.3038, 0.3…</code></pre>
<p>First our data is split into train and test sets. The model is fed
the train set to learn from to then make on the test set.</p>
<pre class="r"><code>set.seed(123) #Ensuring reproducibility

#Getting the split
split = sample.split(data_sub$WIND_SPEED, SplitRatio = 2/3)

#Dividing into train and test set
train_set = subset(data_sub, split == TRUE)
test_set = subset(data_sub, split == FALSE)</code></pre>
<pre class="r"><code>View(train_set)
View(test_set)
nrow(train_set)  #Dsiplay the number of rows the train set</code></pre>
<pre><code>## [1] 165</code></pre>
<pre class="r"><code>#Display the number of rows in the test set
nrow(test_set)</code></pre>
<pre><code>## [1] 83</code></pre>
<div id="feature-scaling" class="section level4">
<h4>Feature Scaling</h4>
<p>To ensure that the independent variables or features in a dataset are
on a similar scale, a preprocessing technique called feature scaling is
used in machine learning. This technique involves transforming the
values of the features so that they fall within a range, which is often
between 0 and 1 or with a mean of 0 and a standard deviation of 1.</p>
<pre class="r"><code># Applying feature Scaling
training_set = scale(train_set)
testing_set = scale(test_set)


#Building the model

Svr_Wind &lt;- svm(formula &lt;- WIND_SPEED ~ ., data &lt;- training_set, 
                              type &lt;- &#39;eps-regression&#39;)</code></pre>
<p>From the code block above, the train and test set of the SVR is
scaled. It requires scaling because it is sensitive to the scale of the
input features.</p>
<p>This involves testing the support vector regression model on the test
set to see its predictions</p>
<pre class="r"><code># Predict wind speed on testing data
y_pred &lt;- predict(Svr_Wind, testing_set)
y_pred</code></pre>
<pre><code>##           2           4           5           8          11          13 
## -0.37588189 -0.20116276 -0.19076999  0.15393226  0.65106589  1.06520492 
##          16          20          21          22          24          25 
##  0.93264315 -0.16547212 -0.10773647 -0.13506149  0.43414870 -0.30025288 
##          26          31          32          33          34          37 
## -0.29985512 -0.08049900  0.05349282 -0.20405540 -0.21200058 -0.87347695 
##          50          53          58          59          61          65 
## -0.30024607 -0.59447796 -0.42296331 -0.05990120 -0.62090590  0.39361344 
##          67          68          69          71          73          82 
##  0.23947215 -0.27641142  0.42593250  0.47497880  0.48435752 -0.05790049 
##          84          87          88          89          94          97 
## -0.09120850  0.31595070  0.27592279  0.12239497  0.18280013  0.25175327 
##         104         106         107         111         114         115 
##  0.37072312  0.13679586  0.14051110 -0.19869121  0.35098532  0.26877009 
##         118         126         130         132         133         134 
## -0.41740026  0.49850241  0.09893749 -0.14280694 -0.07509442 -0.23013372 
##         136         137         138         139         145         150 
##  0.58202962  0.34789671  0.25899850  0.26803510  0.47044362 -0.40558408 
##         151         167         173         174         175         179 
## -0.48383121  0.02998213 -0.02723797 -0.59111888 -0.25948258  0.38402211 
##         181         183         189         190         193         195 
## -0.89278170 -0.41418468 -0.81702689 -0.12744448  0.38071304  0.25629567 
##         198         202         206         214         216         219 
## -0.10424598  0.32417458  0.52630007 -0.39508351  0.06505709  0.37077916 
##         220         222         223         224         229         230 
##  0.19022163  0.39272573  0.67527573  0.10726098 -0.40384842  0.07077143 
##         238         240         242         246         248 
## -0.37277731 -0.42480113 -0.15058171 -0.15652182  0.17146297</code></pre>
<pre class="r"><code>#Changing the scaled train and test set to dataframes
testing_set1 &lt;- data.frame(testing_set)
training_set1 &lt;- data.frame(training_set)</code></pre>
<p>These were converted to dataframes to make it easier to calculate the
required evaluation metrics. Evaluation metrics serve as quantitative
measures to assess the performance of machine learning models. They
provide valuable insights into how well a model has learned from the
data and its capability to make accurate predictions on new, unseen
data.</p>
<p>1.) Mean Squared Error (MSE): The average of the squared differences
between the predicted and actual values. It measures the average squared
deviation of the predictions from the actual values.</p>
<p>2.) Mean Absolute Error (MAE): The average of the absolute
differences between the predicted and actual values. It measures the
average absolute deviation of the predictions from the actual
values.</p>
<p>3.) Root Mean Squared Error (RMSE): The square root of the MSE. It
provides a measure of the typical error magnitude in the
predictions.</p>
<p>4.) R-squared (R²): The proportion of the variance in the target
variable that is explained by the model. It measures the goodness of fit
of the model to the data.</p>
<pre class="r"><code># Calculate evaluation metrics
mae_svr &lt;- mean(abs(testing_set1$WIND_SPEED - y_pred))
mse_svr &lt;- mean((testing_set1$WIND_SPEED - y_pred)^2)
rmse_svr &lt;- sqrt(mean((testing_set1$WIND_SPEED - y_pred)^2))
r2_svr &lt;- cor(testing_set1$WIND_SPEED, y_pred)^2


# Print the evaluation metrics
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_svr))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 0.798240100285463&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_svr))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 1.01229169065539&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_svr))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 1.00612707480486&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Rsquared (RMSE): &quot;, r2_svr))</code></pre>
<pre><code>## [1] &quot;Rsquared (RMSE):  0.0273789558448511&quot;</code></pre>
</div>
<div id="svr-visualisation" class="section level4">
<h4>SVR Visualisation</h4>
<p>This is done to visually assess how the SVR model performed.</p>
<pre class="r"><code>#Create a scatterplot of actual vs predicted wind speeds
ggplot(testing_set1, aes(x = WIND_SPEED, y = y_pred)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Wind Speed&quot;, y = &quot;Predicted Wind Speed&quot;, title = &quot;SVR Model: Actual vs Predicted Wind Speeds&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<p>From the above plot. It can be seen that the model did not accurately
capture the points as they do not fall along or close to the regression
line.</p>
</div>
</div>
<div id="decision-tree-regression" class="section level3">
<h3>Decision Tree Regression</h3>
<pre class="r"><code>#Decision Tree doesn&#39;t require feature scaling

#Building the model
DT_Wind = rpart(formula = WIND_SPEED ~ .,  data = train_set,
                  control = rpart.control(minsplit = 2))
                 


y_pred_DT &lt;- predict(DT_Wind, test_set)
y_pred_DT</code></pre>
<pre><code>##        2        4        5        8       11       13       16       20 
## 2.311111 2.311111 3.365000 3.357000 3.955000 5.877500 3.955000 5.450833 
##       21       22       24       25       26       31       32       33 
## 3.365000 2.176667 5.450833 2.311111 6.600000 1.748182 1.748182 0.875000 
##       34       37       50       53       58       59       61       65 
## 5.380000 2.176667 0.875000 2.176667 1.982857 1.040000 3.438182 5.450833 
##       67       68       69       71       73       82       84       87 
## 3.357000 1.424545 5.450833 5.450833 3.955000 2.311111 5.450833 5.450833 
##       88       89       94       97      104      106      107      111 
## 5.450833 1.748182 1.748182 2.311111 5.450833 3.357000 3.357000 3.438182 
##      114      115      118      126      130      132      133      134 
## 3.357000 3.357000 5.215000 4.196364 3.357000 5.450833 5.450833 3.365000 
##      136      137      138      139      145      150      151      167 
## 4.196364 3.357000 3.357000 3.357000 5.380000 1.615000 1.615000 2.176667 
##      173      174      175      179      181      183      189      190 
## 5.450833 1.424545 1.424545 3.357000 3.375000 3.375000 1.424545 5.215000 
##      193      195      198      202      206      214      216      219 
## 1.040000 3.992857 3.992857 3.955000 6.900000 2.250000 2.250000 3.992857 
##      220      222      223      224      229      230      238      240 
## 3.992857 5.565000 5.565000 5.565000 2.176667 5.565000 1.748182 1.748182 
##      242      246      248 
## 3.992857 5.565000 2.250000</code></pre>
<pre class="r"><code># Calculate evaluation metrics
mae_DT &lt;- mean(abs(test_set$WIND_SPEED - y_pred_DT))
mse_DT &lt;- mean((test_set$WIND_SPEED - y_pred_DT)^2)
rmse_DT &lt;- sqrt(mean((test_set$WIND_SPEED - y_pred_DT)^2))
r2_DT &lt;- cor(test_set$WIND_SPEED, y_pred_DT)^2


# Print the evaluation metrics
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_DT))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 1.44404096907109&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_DT))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 3.38738894019642&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_DT))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 1.8404860608536&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;R Squared (R2): &quot;, r2_DT))</code></pre>
<pre><code>## [1] &quot;R Squared (R2):  0.119035999207337&quot;</code></pre>
<div id="decision-tree-visualisation" class="section level4">
<h4>Decision Tree Visualisation</h4>
<pre class="r"><code>#Create a scatterplot of actual vs predicted wind speeds
ggplot(test_set, aes(x = WIND_SPEED, y = y_pred_DT)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Wind Speed&quot;, y = &quot;Predicted Wind Speed&quot;, title = &quot;DT Model: Actual vs Predicted Wind Speeds&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>As seen from the figure above, just like the SVR, its points do not
fall along the regression line. From the plot, this is a poor performing
model</p>
</div>
</div>
<div id="random-forest-regression" class="section level3">
<h3>Random Forest Regression</h3>
<pre class="r"><code>set.seed(1234) #Ensures reproducibility
RF_wind200 &lt;-  randomForest(x = train_set,y = train_set$WIND_SPEED, ntree = 200)
                         
# Number of trees (500)
RF_wind500 = randomForest(x = train_set, y = train_set$WIND_SPEED, ntree = 500)</code></pre>
<pre class="r"><code>#Testing the Random Forest Model on the test set
y_pred_RF200 = predict(RF_wind200, test_set)
y_pred_RF200</code></pre>
<pre><code>##        2        4        5        8       11       13       16       20 
## 3.913608 4.167978 5.611962 5.405715 6.733402 5.543069 3.728571 2.590226 
##       21       22       24       25       26       31       32       33 
## 3.086675 4.062254 2.886408 4.365439 3.154892 2.209606 2.196473 1.757358 
##       34       37       50       53       58       59       61       65 
## 1.757306 1.894355 1.428881 2.003251 1.432019 1.505005 4.218023 2.685042 
##       67       68       69       71       73       82       84       87 
## 1.897704 2.787681 4.758316 4.052881 4.249949 2.753548 6.018524 5.678838 
##       88       89       94       97      104      106      107      111 
## 4.956237 3.712235 1.457909 1.720113 3.960783 3.123889 3.178072 4.946592 
##      114      115      118      126      130      132      133      134 
## 1.941303 3.025526 3.025976 4.927974 3.770892 3.906635 3.650923 3.026831 
##      136      137      138      139      145      150      151      167 
## 4.144943 2.515238 1.821216 1.782113 1.849764 2.506864 2.617560 3.080223 
##      173      174      175      179      181      183      189      190 
## 4.285383 4.577974 4.556397 3.781193 4.427278 5.252203 4.020678 5.480378 
##      193      195      198      202      206      214      216      219 
## 4.360680 4.082834 2.570652 4.061203 6.468532 4.902157 2.189418 2.566054 
##      220      222      223      224      229      230      238      240 
## 2.435048 2.860418 4.814437 5.275627 5.300962 5.635571 1.902262 1.700850 
##      242      246      248 
## 1.879805 3.203623 4.981159</code></pre>
<pre class="r"><code>View(test_set)</code></pre>
<pre class="r"><code>y_pred_RF500 &lt;- predict(RF_wind500, test_set)
y_pred_RF500</code></pre>
<pre><code>##        2        4        5        8       11       13       16       20 
## 3.765303 4.118135 5.541303 5.388613 6.847253 5.448367 3.813080 2.600294 
##       21       22       24       25       26       31       32       33 
## 3.133837 4.135418 2.905827 4.399816 3.302861 2.255830 2.242787 1.681286 
##       34       37       50       53       58       59       61       65 
## 1.652875 1.966709 1.386208 2.000034 1.428658 1.608671 4.152920 2.616896 
##       67       68       69       71       73       82       84       87 
## 1.823334 2.808379 4.712517 4.088421 4.271539 2.771156 5.862058 5.696339 
##       88       89       94       97      104      106      107      111 
## 4.968025 3.651047 1.517572 1.766159 3.927430 3.070859 3.081882 4.808749 
##      114      115      118      126      130      132      133      134 
## 1.841977 2.928508 3.058709 4.881677 3.686156 3.853764 3.674324 3.014836 
##      136      137      138      139      145      150      151      167 
## 4.158536 2.449217 1.850989 1.830009 1.732561 2.445284 2.544615 3.048773 
##      173      174      175      179      181      183      189      190 
## 4.291191 4.574443 4.566792 3.779561 4.377348 5.089523 4.000011 5.447188 
##      193      195      198      202      206      214      216      219 
## 4.350449 4.062522 2.628380 4.034232 6.439641 4.976699 2.243255 2.575934 
##      220      222      223      224      229      230      238      240 
## 2.483481 2.915343 4.864550 5.309169 5.232758 5.693330 1.879583 1.704246 
##      242      246      248 
## 1.877873 3.247585 5.012589</code></pre>
<pre class="r"><code># Calculate evaluation metrics for n = 200
mae_RF200 &lt;- mean(abs(test_set$WIND_SPEED - y_pred_RF200))
mse_RF200 &lt;- mean((test_set$WIND_SPEED - y_pred_RF200)^2)
rmse_RF200 &lt;- sqrt(mean((test_set$WIND_SPEED - y_pred_RF200)^2))
r2_RF200 &lt;- cor(test_set$WIND_SPEED, y_pred_RF200)^2


# Print the evaluation metrics for n = 200
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_RF200))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 0.261388684738956&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_RF200))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 0.192092643235467&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_RF200))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 0.438283747400547&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;R Squared (R2): &quot;, r2_RF200))</code></pre>
<pre><code>## [1] &quot;R Squared (R2):  0.955490709250913&quot;</code></pre>
<pre class="r"><code># Calculate evaluation metrics for n = 500
mae_RF500 &lt;- mean(abs(test_set$WIND_SPEED - y_pred_RF500))
mse_RF500 &lt;- mean((test_set$WIND_SPEED - y_pred_RF500)^2)
rmse_RF500 &lt;- sqrt(mean((test_set$WIND_SPEED - y_pred_RF500)^2))
r2_RF500 &lt;- cor(test_set$WIND_SPEED, y_pred_RF500)^2


# Print the evaluation metrics for n = 500
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_RF500))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 0.270336&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_RF500))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 0.201838534963385&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_RF500))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 0.449264437679397&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;R Squared (R2): &quot;, r2_RF500))</code></pre>
<pre><code>## [1] &quot;R Squared (R2):  0.952551906459685&quot;</code></pre>
<div id="visualisations-for-random-forest-regression"
class="section level4">
<h4>Visualisations for Random Forest Regression</h4>
<pre class="r"><code>ggplot(test_set, aes(x = WIND_SPEED, y = y_pred_RF200)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Wind Speed&quot;, y = &quot;Predicted Wind Speed&quot;, title = &quot;RF Model (Trees = 200): Actual vs Predicted Wind Speeds&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<p>From the plot, the points on or around the regression line. This is
the ideal requirement.</p>
<pre class="r"><code>ggplot(test_set, aes(x = WIND_SPEED, y = y_pred_RF500)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Wind Speed&quot;, y = &quot;Predicted Wind Speed&quot;, title = &quot;RF Model (Trees = 500): Actual vs Predicted Wind Speeds&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
</div>
</div>
<div id="model-comaprisons" class="section level3">
<h3>Model Comaprisons</h3>
<p>This is done to compare the different models based on their
evaluation metrics.</p>
<pre class="r"><code># Create a dataframe with model names and evaluation metrics
models &lt;- c(&quot;SVR&quot;, &quot;Decision Tree&quot;, &quot;Random Forest&quot;)
mse &lt;- c(mse_svr, mse_DT,mse_RF200)  
mae &lt;- c(mae_svr, mae_DT, mae_RF200)  
rmse &lt;- c(rmse_svr, rmse_DT, rmse_RF200) 
rsquared &lt;- c(r2_svr, r2_DT, r2_RF200)  

eval_df &lt;- data.frame(Model = rep(models, each = 4),
                   Metric = rep(c(&quot;MSE&quot;, &quot;MAE&quot;, &quot;RMSE&quot;, &quot;R-squared&quot;), times = 3),
                   Value = c(mse, mae, rmse, rsquared))

# Create a grouped bar plot
ggplot(eval_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) +
  labs(title = &quot;Comparison of Model Evaluation Metrics&quot;,
       x = &quot;Model&quot;, y = &quot;Value&quot;) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p>From the graph, it can be confidently said that the best model is the
Random Forest regression model.</p>
<p>Creating a sample dataframe to test out the models</p>
<pre class="r"><code>TSK &lt;- c(298.30, 297.70, 305.50, 295.30)
Q2 &lt;- c(0.011140, 0.003700, 0.007400, 0.004505)
RAINNC &lt;- c(0.1, 4.2, 5.5, 6.2)
TSLB &lt;- c(298.4, 283.50, 279.90, 295.60)
SMOIS &lt;- c(0.31320, 0.40060, 0.31980, 0.32470)
WIND_SPEED &lt;- c(5.5,6.5,4.2,3.5)
Model_test &lt;- data.frame(TSK,Q2,RAINNC,TSLB,SMOIS,WIND_SPEED)
Test_prediction1 &lt;- predict(Svr_Wind, Model_test)

Test_prediction1</code></pre>
<pre><code>##         1         2         3         4 
## 0.1736683 0.1736683 0.1736683 0.1736683</code></pre>
<pre class="r"><code>View(Model_test)</code></pre>
<pre class="r"><code>Test_prediction2 &lt;- predict(DT_Wind, Model_test)
Test_prediction2</code></pre>
<pre><code>##     1     2     3     4 
## 5.565 3.955 3.955 6.900</code></pre>
<pre class="r"><code>Test_prediction3 &lt;- predict(RF_wind200, Model_test)
Test_prediction3</code></pre>
<pre><code>##        1        2        3        4 
## 5.296704 5.639182 4.964705 3.867882</code></pre>
</div>
</div>
<div id="research-question-5" class="section level2">
<h2>Research Question 5</h2>
<p>How can Surface temperature be predicted based on a combination of
meteorological variables using machine learning techniques, given that
Birmingham experiences the urban heat island effect and how does the
predictive performance vary across different machine learning
models?</p>
<pre class="r"><code>data_sub1 &lt;- data_weather[c(&quot;TSK&quot;, &quot;PSFC&quot;, &quot;Q2&quot;, &quot;RAINNC&quot;, &quot;WIND_SPEED&quot;,&quot;TSLB&quot;)]
glimpse(data_sub1)</code></pre>
<pre><code>## Rows: 248
## Columns: 6
## $ TSK        &lt;dbl&gt; 277.6, 276.3, 277.6, 287.4, 293.2, 287.4, 283.7, 281.7, 280…
## $ PSFC       &lt;dbl&gt; 99325, 99313, 99300, 99255, 99163, 99071, 99018, 98863, 986…
## $ Q2         &lt;dbl&gt; 0.003770, 0.003540, 0.003800, 0.004085, 0.004370, 0.004790,…
## $ RAINNC     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 4.1, 6.1,…
## $ WIND_SPEED &lt;dbl&gt; 3.86, 3.61, 2.24, 4.39, 6.86, 6.49, 6.68, 6.54, 6.60, 8.97,…
## $ TSLB       &lt;dbl&gt; 278.90, 277.60, 277.30, 283.20, 289.40, 287.90, 284.80, 282…</code></pre>
<pre class="r"><code>Model_PSFC &lt;- PSFC ~ TSK + Q2+ RAINNC + WIND_SPEED + TSLB 

#Fitting the model
Linear_PSFC &lt;- lm(Model_PSFC, data = data_sub1)

raintest(Linear_PSFC)</code></pre>
<pre><code>## 
##  Rainbow test
## 
## data:  Linear_PSFC
## Rain = 0.83572, df1 = 124, df2 = 118, p-value = 0.838</code></pre>
<div id="support-vector-regression-1" class="section level3">
<h3>Support Vector Regression</h3>
<pre class="r"><code>set.seed(123) #Ensuring reproducibility

unique(colnames(data_weather))</code></pre>
<pre><code>##  [1] &quot;TSK&quot;        &quot;PSFC&quot;       &quot;U10&quot;        &quot;V10&quot;        &quot;Q2&quot;        
##  [6] &quot;RAINC&quot;      &quot;RAINNC&quot;     &quot;SNOW&quot;       &quot;TSLB&quot;       &quot;SMOIS&quot;     
## [11] &quot;DATETIME&quot;   &quot;WIND_SPEED&quot;</code></pre>
<pre class="r"><code>#Getting the split
split1 = sample.split(data_sub1$TSK, SplitRatio = 0.8)

#Dividing into train and test set
train_set = subset(data_sub1, split == TRUE)
test_set = subset(data_sub1, split == FALSE)</code></pre>
<pre class="r"><code>View(train_set)
View(test_set)
nrow(train_set)  #Dsiplay the number of rows the train set</code></pre>
<pre><code>## [1] 165</code></pre>
<pre class="r"><code># Applying feature Scaling
training_set = scale(train_set)
testing_set = scale(test_set)

#Building the model

Svr_TSK &lt;- svm(formula &lt;- TSK ~ ., data &lt;- training_set, 
                type &lt;- &#39;eps-regression&#39;)

# Predict wind speed on testing data
y_pred &lt;- predict(Svr_TSK, testing_set)
y_pred</code></pre>
<pre><code>##            2            4            5            8           11           13 
## -1.632475082 -0.838205926  0.060620851 -0.939299192 -0.281696877 -0.102713426 
##           16           20           21           22           24           25 
## -0.353114970 -0.493872336  0.603332508  1.006787082 -0.456874490 -1.268795859 
##           26           31           32           33           34           37 
## -1.310554312  1.224842972  0.232061469 -0.988360885 -1.017845929  1.061537256 
##           50           53           58           59           61           65 
## -0.646422404  1.557507557 -0.301385880 -0.365333942  1.082187343 -0.695220175 
##           67           68           69           71           73           82 
## -1.026451755 -0.023543805 -0.192450047 -0.600612327 -0.950409418 -1.298563720 
##           84           87           88           89           94           97 
## -0.289198010 -0.200046991 -0.471559808 -0.811755166 -0.027132690 -0.771978955 
##          104          106          107          111          114          115 
##  0.169598532 -1.112337868 -1.134197477  0.730550460 -0.978520404 -1.038687641 
##          118          126          130          132          133          134 
##  1.928292700 -0.814915007 -1.251847955 -0.451135073  0.801099056  0.947823778 
##          136          137          138          139          145          150 
## -0.616794154 -1.013101642 -0.858710623 -0.803615214 -0.676115228  2.000901017 
##          151          167          173          174          175          179 
##  1.755658813  1.082959584 -0.177821877  0.372711864  0.364836963 -1.044372968 
##          181          183          189          190          193          195 
##  0.935691979  0.785928352 -0.009426943  1.165117860 -0.165011991 -0.554717395 
##          198          202          206          214          216          219 
##  0.009648216 -0.478764420  1.050909835  1.592182376  0.591026123 -0.305569311 
##          220          222          223          224          229          230 
## -0.191077450  1.787424420  1.813015633  0.990674824  0.893175305  1.227878630 
##          238          240          242          246          248 
##  0.064510374 -0.163835673 -0.419123878  1.494278166  0.910333806</code></pre>
<pre class="r"><code>#Changing the scaled train and test set to dataframes
testing_set1 &lt;- data.frame(testing_set)
training_set1 &lt;- data.frame(training_set)</code></pre>
<pre class="r"><code># Calculate evaluation metrics
mae_svr &lt;- mean(abs(testing_set1$TSK - y_pred))
mse_svr &lt;- mean((testing_set1$TSK - y_pred)^2)
rmse_svr &lt;- sqrt(mean((testing_set1$TSK- y_pred)^2))
r2_svr &lt;- cor(testing_set1$TSK, y_pred)^2


# Print the evaluation metrics
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_svr))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 0.272828637221568&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_svr))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 0.124090734479886&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_svr))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 0.352265147977892&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Rsquared (RMSE): &quot;, r2_svr))</code></pre>
<pre><code>## [1] &quot;Rsquared (RMSE):  0.874434013773486&quot;</code></pre>
<div id="svr-visualisation-1" class="section level4">
<h4>SVR Visualisation</h4>
<p>This is done to visually assess how the SVR model performed.</p>
<pre class="r"><code>#Create a scatterplot of actual vs predicted wind speeds
ggplot(testing_set1, aes(x = TSK, y = y_pred)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Surface Temperature&quot;, y = &quot;Predicted Surface Temperature&quot;, title = &quot;SVR Model: Actual vs Predicted Surface Temperature&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-92-1.png" width="672" /></p>
<p>From the plot above, it can be seen that the all points fell around
the regression line.</p>
</div>
</div>
<div id="decision-tree-regression-1" class="section level3">
<h3>Decision Tree Regression</h3>
<pre class="r"><code>#Decision Tree doesn&#39;t require feature scaling

#Building the model
DT_TSK = rpart(formula = TSK ~ .,  data = train_set,
                control = rpart.control(minsplit = 2))



y_pred_DT &lt;- predict(DT_TSK, test_set)
y_pred_DT</code></pre>
<pre><code>##        2        4        5        8       11       13       16       20 
## 281.2880 281.2880 288.8054 281.2880 281.2880 288.8054 285.1722 285.1722 
##       21       22       24       25       26       31       32       33 
## 288.8054 294.7000 285.1722 281.2880 281.2880 294.7000 288.8054 281.2880 
##       34       37       50       53       58       59       61       65 
## 281.2880 294.7000 285.1722 300.3519 291.7000 285.1722 300.3519 285.1722 
##       67       68       69       71       73       82       84       87 
## 281.2880 288.8054 288.8054 285.1722 285.1722 281.2880 288.8054 288.8054 
##       88       89       94       97      104      106      107      111 
## 285.1722 285.1722 291.7000 285.1722 288.8054 281.2880 281.2880 294.7000 
##      114      115      118      126      130      132      133      134 
## 281.2880 281.2880 300.3519 285.1722 281.2880 285.1722 294.7000 294.7000 
##      136      137      138      139      145      150      151      167 
## 285.1722 281.2880 281.2880 281.2880 285.1722 300.3519 300.3519 300.3519 
##      173      174      175      179      181      183      189      190 
## 288.8054 294.7000 294.7000 281.2880 294.7000 300.3519 288.8054 300.3519 
##      193      195      198      202      206      214      216      219 
## 288.8054 285.1722 288.8054 285.1722 300.3519 300.3519 294.7000 288.8054 
##      220      222      223      224      229      230      238      240 
## 288.8054 300.3519 300.3519 294.7000 294.7000 300.3519 288.8054 291.7000 
##      242      246      248 
## 285.1722 300.3519 294.7000</code></pre>
<pre class="r"><code># Calculate evaluation metrics
mae_DT &lt;- mean(abs(test_set$TSK - y_pred_DT))
mse_DT &lt;- mean((test_set$TSK - y_pred_DT)^2)
rmse_DT &lt;- sqrt(mean((test_set$TSK - y_pred_DT)^2))
r2_DT &lt;- cor(test_set$TSK, y_pred_DT)^2


# Print the evaluation metrics
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_DT))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 2.22446769661226&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_DT))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 7.70638651005212&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_DT))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 2.77603791581673&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;R Squared (R2): &quot;, r2_DT))</code></pre>
<pre><code>## [1] &quot;R Squared (R2):  0.843189915436262&quot;</code></pre>
<div id="decision-tree-visualisation-1" class="section level4">
<h4>Decision Tree Visualisation</h4>
<pre class="r"><code>#Create a scatterplot of actual vs predicted wind speeds
ggplot(test_set, aes(x = TSK, y = y_pred_DT)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Wind Speed&quot;, y = &quot;Predicted Wind Speed&quot;, title = &quot;DT Model: Actual vs Predicted Wind Speeds&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-95-1.png" width="672" /></p>
<p>From the visualisation above, this is a not so good model.</p>
</div>
</div>
<div id="random-forest-regression-1" class="section level3">
<h3>Random Forest Regression</h3>
<pre class="r"><code>set.seed(1234) #Ensures reproducibility
RF_wind200 &lt;-  randomForest(x = train_set,y = train_set$TSK, ntree = 200)


#Testing the Random Forest Model on the test set
y_pred_RF200 = predict(RF_wind200, test_set)
y_pred_RF200</code></pre>
<pre><code>##        2        4        5        8       11       13       16       20 
## 279.6261 285.2710 291.9363 281.7361 281.9305 292.1697 282.9170 287.4193 
##       21       22       24       25       26       31       32       33 
## 293.3176 295.4627 285.0837 281.3375 281.7660 295.2910 288.4408 282.5028 
##       34       37       50       53       58       59       61       65 
## 281.8434 297.6162 284.3429 301.0681 286.9227 286.8077 299.3886 283.7976 
##       67       68       69       71       73       82       84       87 
## 282.7937 291.0952 287.4950 284.8618 284.4555 280.5204 289.1256 287.7524 
##       88       89       94       97      104      106      107      111 
## 285.3956 283.5968 287.9204 283.7417 287.7813 281.4327 282.0526 294.2775 
##      114      115      118      126      130      132      133      134 
## 282.1349 283.6027 301.8145 284.6494 280.7506 288.0486 291.8242 292.7088 
##      136      137      138      139      145      150      151      167 
## 284.1303 281.6612 281.3964 282.3240 283.8800 301.9834 297.6454 296.4544 
##      173      174      175      179      181      183      189      190 
## 289.3794 294.3871 293.2384 282.9267 298.2222 296.6215 293.4859 297.1407 
##      193      195      198      202      206      214      216      219 
## 287.2491 286.6738 289.2866 285.8087 300.8879 301.3025 293.4778 287.0207 
##      220      222      223      224      229      230      238      240 
## 287.9231 302.4302 299.5148 294.3175 298.8566 297.7221 289.7351 287.6965 
##      242      246      248 
## 285.8839 301.7655 294.7476</code></pre>
<pre class="r"><code># Calculate evaluation metrics for n = 200
mae_RF200 &lt;- mean(abs(test_set$TSK - y_pred_RF200))
mse_RF200 &lt;- mean((test_set$TSK - y_pred_RF200)^2)
rmse_RF200 &lt;- sqrt(mean((test_set$TSK - y_pred_RF200)^2))
r2_RF200 &lt;- cor(test_set$TSK, y_pred_RF200)^2


# Print the evaluation metrics for n = 200
print(paste(&quot;Mean Absolute Error (MAE):&quot;, mae_RF200))</code></pre>
<pre><code>## [1] &quot;Mean Absolute Error (MAE): 0.851599297188751&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Mean Squared Error (MSE):&quot;, mse_RF200))</code></pre>
<pre><code>## [1] &quot;Mean Squared Error (MSE): 1.28739094159217&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;Root Mean Squared Error (RMSE):&quot;, rmse_RF200))</code></pre>
<pre><code>## [1] &quot;Root Mean Squared Error (RMSE): 1.13463251389698&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;R Squared (R2): &quot;, r2_RF200))</code></pre>
<pre><code>## [1] &quot;R Squared (R2):  0.976821858581421&quot;</code></pre>
<div id="visualisations-for-random-forest-regression-1"
class="section level4">
<h4>Visualisations for Random Forest Regression</h4>
<pre class="r"><code>ggplot(test_set, aes(x = TSK, y = y_pred_RF200)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) +  # Add diagonal line
  labs(x = &quot;Actual Wind Speed&quot;, y = &quot;Predicted Wind Speed&quot;, title = &quot;RF Model (Trees = 200): Actual vs Predicted Wind Speeds&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-98-1.png" width="672" /></p>
<p>From the plot above, this is also a relatively good model</p>
</div>
</div>
<div id="model-comaprisons-1" class="section level3">
<h3>Model Comaprisons</h3>
<p>This is done to determine the best model</p>
<pre class="r"><code># Create a dataframe with model names and evaluation metrics
models &lt;- c(&quot;SVR&quot;, &quot;Decision Tree&quot;, &quot;Random Forest&quot;)
mse &lt;- c(mse_svr, mse_DT,mse_RF200)  
mae &lt;- c(mae_svr, mae_DT, mae_RF200)  
rmse &lt;- c(rmse_svr, rmse_DT, rmse_RF200) 
rsquared &lt;- c(r2_svr, r2_DT, r2_RF200)  

eval_df1 &lt;- data.frame(Model = rep(models, each = 4),
                      Metric = rep(c(&quot;MSE&quot;, &quot;MAE&quot;, &quot;RMSE&quot;, &quot;R-squared&quot;), times = 3),
                      Value = c(mse, mae, rmse, rsquared))

# Create a grouped bar plot
ggplot(eval_df1, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) +
  labs(title = &quot;Comparison of Model Evaluation Metrics&quot;,
       x = &quot;Model&quot;, y = &quot;Value&quot;) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
<p>From the comparisons of the model, it cannot be outrightly decided
what the best model is. The best model now is dependent on the
evaluation metric that is under consideration, But overall, the Decision
tree is seen as the worse model.</p>
</div>
</div>
</div>
<div id="time-series-analysis" class="section level1">
<h1>Time Series Analysis</h1>
<p>Time series analysis involves analyzing data that has a time
component using specialized tools and techniques.</p>
<div id="research-question-6" class="section level2">
<h2>Research Question 6</h2>
<p>How does surface temperature vary over time, given that is important
to stakeholders in Birmingham. Are there any trends or patterns and can
the surface temperature for the next 24-hour period be forecasted?</p>
<pre class="r"><code>str(data_weather)</code></pre>
<pre><code>## &#39;data.frame&#39;:    248 obs. of  12 variables:
##  $ TSK       : num  278 276 278 287 293 ...
##  $ PSFC      : num  99325 99313 99300 99255 99163 ...
##  $ U10       : num  3.3 3.5 2 3 4.1 3.6 1.9 0.7 0.2 1.1 ...
##  $ V10       : num  -2 -0.9 1 3.2 5.5 5.4 6.4 6.5 6.6 8.9 ...
##  $ Q2        : num  0.00377 0.00354 0.0038 0.00409 0.00437 ...
##  $ RAINC     : num  0 0 0 0 0 0 0 0 0 0.05 ...
##  $ RAINNC    : num  0 0 0 0 0 0 0 0 0.2 0.6 ...
##  $ SNOW      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TSLB      : num  279 278 277 283 289 ...
##  $ SMOIS     : num  0.312 0.31 0.309 0.307 0.306 ...
##  $ DATETIME  : POSIXct, format: &quot;2018-05-01 00:00:00&quot; &quot;2018-05-01 03:00:00&quot; ...
##  $ WIND_SPEED: num  3.86 3.61 2.24 4.39 6.86 6.49 6.68 6.54 6.6 8.97 ...</code></pre>
<pre class="r"><code>class(data_weather)</code></pre>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
<pre class="r"><code>#Getting the subset of our data required for the time series analysis

Time_df &lt;- data_weather[c(&quot;TSK&quot;, &quot;DATETIME&quot;)]
str(Time_df)</code></pre>
<pre><code>## &#39;data.frame&#39;:    248 obs. of  2 variables:
##  $ TSK     : num  278 276 278 287 293 ...
##  $ DATETIME: POSIXct, format: &quot;2018-05-01 00:00:00&quot; &quot;2018-05-01 03:00:00&quot; ...</code></pre>
<pre class="r"><code>class(Time_df)</code></pre>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
<pre class="r"><code>#Converting the dataframe to a time series class




ts_data &lt;- ts(Time_df$TSK,start = 1,
              frequency = 8)
plot(ts_data)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<p>The plot above shows the trend of the surface tempearture across the
30 day time period.</p>
<p>Seasonal cycles, in the context of time series analysis, refer to
recurring patterns in data that are tied to specific time periods within
a year.</p>
<pre class="r"><code>#Checking for seasonality
plot(decompose(ts_data))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
<p>From the visualisation, the time series data displays a seasonal
patttern.</p>
<p>Stationarity is a feature of time series data whereby its statistical
attributes, such as mean, variance, and autocorrelation, remain
consistent across time. In other words, a time series can be considered
stationary if its statistical properties do not change with time.</p>
<p>To check for stationarity we use the Augmented Dickey-Fuller Test
(ADF)</p>
<pre class="r"><code>#Checking for Stationarity
adf.test(ts_data)</code></pre>
<pre><code>## 
##  Augmented Dickey-Fuller Test
## 
## data:  ts_data
## Dickey-Fuller = -3.0499, Lag order = 6, p-value = 0.1339
## alternative hypothesis: stationary</code></pre>
<p>The p-value is greater than 0.05. This means we fail to reject the
null hypothesis (H0). The null hypothesis is accepted meaning the data
is non-stationary. But the time series needs to be sationary to carry
out time series modelling. To rectify that we carry out
differencing.</p>
<p>Differencing is a techniques that is used to transform a
non-staionary time series to a stationary one.</p>
<pre class="r"><code>#Implementing Differencing
ndiffs(ts_data) # No of differences required to make the data stationary</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>nsdiffs(ts_data) #No of seasonal diiferences required to make the data stationary</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>y1 &lt;- diff(ts_data, lag = 8) # Implementing one seasonal differencing

adf.test(y1)</code></pre>
<pre><code>## Warning in adf.test(y1): p-value smaller than printed p-value</code></pre>
<pre><code>## 
##  Augmented Dickey-Fuller Test
## 
## data:  y1
## Dickey-Fuller = -6.2777, Lag order = 6, p-value = 0.01
## alternative hypothesis: stationary</code></pre>
<p>The p-values is less than 0.05. The null hypothesis is rejected. The
data is now stationary.</p>
<p>Now we plot the differenced time series data to visually assess its
stationarity.</p>
<pre class="r"><code>plot(y1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
<div id="seasonal-arima" class="section level3">
<h3>Seasonal ARIMA</h3>
<p>Since the data is seasonal, we would use seasonal ARIMA</p>
<pre class="r"><code>#Splitting my time series data
split_ratio &lt;- 0.8

# Calculate the number of observations for the training set
train_size &lt;- floor(length(y1) * split_ratio)

# Split the data using indexing
train_data &lt;- y1[1:train_size]
test_data &lt;- y1[(train_size + 1):length(y1)]


length(train_data)</code></pre>
<pre><code>## [1] 192</code></pre>
<pre class="r"><code>length(test_data)</code></pre>
<pre><code>## [1] 48</code></pre>
<div id="acf-and-pacf-plot" class="section level4">
<h4>ACF and PACF Plot</h4>
<pre class="r"><code>#Autocorrelation Function Plot
acfplot &lt;- acf(train_data)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p>From the ACF plot, we can see that the lag spikes starts off strongly
then gradually reduces to zero. There are four positive lag spikes that
are beyond the reference blue dashed line. This means that there is a
strong autocorrelation. All these spikes can serve as the q value.</p>
<pre class="r"><code>#Partial Autocorrelation Plot
pacfplot &lt;- pacf(train_data)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<p>From the PACF plot, there is lag spike at lag 1 then another at lag
2. It shows the order of the Auto-Regressive terms.</p>
<pre class="r"><code>#Fitting the seasonal arima model
sarima_model &lt;- auto.arima(train_data, trace= TRUE, seasonal=TRUE, stepwise = FALSE, approximation = FALSE, allowdrift = FALSE)</code></pre>
<pre><code>## 
##  ARIMA(0,0,0) with zero mean     : 1123.906
##  ARIMA(0,0,0) with non-zero mean : 1125.545
##  ARIMA(0,0,1) with zero mean     : 1004.82
##  ARIMA(0,0,1) with non-zero mean : 1006.594
##  ARIMA(0,0,2) with zero mean     : 964.2608
##  ARIMA(0,0,2) with non-zero mean : 966.1735
##  ARIMA(0,0,3) with zero mean     : 958.0449
##  ARIMA(0,0,3) with non-zero mean : 960.0264
##  ARIMA(0,0,4) with zero mean     : 961.7668
##  ARIMA(0,0,4) with non-zero mean : 963.7817
##  ARIMA(0,0,5) with zero mean     : 961.1939
##  ARIMA(0,0,5) with non-zero mean : 963.2283
##  ARIMA(1,0,0) with zero mean     : 972.8999
##  ARIMA(1,0,0) with non-zero mean : 974.8981
##  ARIMA(1,0,1) with zero mean     : 962.4474
##  ARIMA(1,0,1) with non-zero mean : 964.4349
##  ARIMA(1,0,2) with zero mean     : 959.6343
##  ARIMA(1,0,2) with non-zero mean : 961.6273
##  ARIMA(1,0,3) with zero mean     : 953.804
##  ARIMA(1,0,3) with non-zero mean : 955.7752
##  ARIMA(1,0,4) with zero mean     : Inf
##  ARIMA(1,0,4) with non-zero mean : 954.7241
##  ARIMA(2,0,0) with zero mean     : 960.0354
##  ARIMA(2,0,0) with non-zero mean : 961.9916
##  ARIMA(2,0,1) with zero mean     : 962.1169
##  ARIMA(2,0,1) with non-zero mean : 964.0964
##  ARIMA(2,0,2) with zero mean     : 961.702
##  ARIMA(2,0,2) with non-zero mean : 963.7124
##  ARIMA(2,0,3) with zero mean     : 954.0464
##  ARIMA(2,0,3) with non-zero mean : 956.0326
##  ARIMA(3,0,0) with zero mean     : 962.1124
##  ARIMA(3,0,0) with non-zero mean : 964.0929
##  ARIMA(3,0,1) with zero mean     : 963.9822
##  ARIMA(3,0,1) with non-zero mean : 965.9785
##  ARIMA(3,0,2) with zero mean     : Inf
##  ARIMA(3,0,2) with non-zero mean : Inf
##  ARIMA(4,0,0) with zero mean     : 961.182
##  ARIMA(4,0,0) with non-zero mean : 963.2248
##  ARIMA(4,0,1) with zero mean     : 963.2293
##  ARIMA(4,0,1) with non-zero mean : 965.2943
##  ARIMA(5,0,0) with zero mean     : 962.9709
##  ARIMA(5,0,0) with non-zero mean : 965.0308
## 
## 
## 
##  Best model: ARIMA(1,0,3) with zero mean</code></pre>
<pre class="r"><code>sarima_model</code></pre>
<pre><code>## Series: train_data 
## ARIMA(1,0,3) with zero mean 
## 
## Coefficients:
##           ar1     ma1     ma2     ma3
##       -0.7891  1.7966  1.2845  0.4802
## s.e.   0.0791  0.1133  0.1447  0.0551
## 
## sigma^2 = 8.034:  log likelihood = -471.74
## AIC=953.48   AICc=953.8   BIC=969.77</code></pre>
<pre class="r"><code>forecast1 &lt;- forecast(sarima_model, h=length(test_data))
forecast1</code></pre>
<pre><code>##     Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95
## 193  -3.954529e-01 -4.028388 3.237483 -5.951548 5.160642
## 194   5.623788e-01 -4.594103 5.718860 -7.323779 8.448537
## 195   1.017171e-01 -5.352775 5.556210 -8.240209 8.443644
## 196  -8.026635e-02 -5.545396 5.384864 -8.438462 8.277929
## 197   6.333926e-02 -5.408404 5.535083 -8.304971 8.431649
## 198  -4.998186e-02 -5.525840 5.425876 -8.424584 8.324620
## 199   3.944136e-02 -5.438977 5.517860 -8.339076 8.417959
## 200  -3.112371e-02 -5.511136 5.448888 -8.412079 8.349831
## 201   2.456014e-02 -5.456444 5.505564 -8.357912 8.407033
## 202  -1.938074e-02 -5.501003 5.462241 -8.402798 8.364037
## 203   1.529360e-02 -5.466713 5.497300 -8.368712 8.399299
## 204  -1.206839e-02 -5.494314 5.470178 -8.396440 8.372303
## 205   9.523326e-03 -5.472872 5.491919 -8.375077 8.394123
## 206  -7.514985e-03 -5.490003 5.474973 -8.392257 8.377227
## 207   5.930176e-03 -5.476616 5.488476 -8.378900 8.390761
## 208  -4.679581e-03 -5.487261 5.477902 -8.389565 8.380206
## 209   3.692721e-03 -5.478912 5.486297 -8.381227 8.388612
## 210  -2.913976e-03 -5.485532 5.479704 -8.387855 8.382027
## 211   2.299458e-03 -5.480328 5.484926 -8.382655 8.387254
## 212  -1.814533e-03 -5.484447 5.480818 -8.386777 8.383148
## 213   1.431872e-03 -5.481204 5.484068 -8.383536 8.386400
## 214  -1.129910e-03 -5.483768 5.481508 -8.386101 8.383841
## 215   8.916270e-04 -5.481748 5.483531 -8.384081 8.385865
## 216  -7.035949e-04 -5.483344 5.481936 -8.385678 8.384271
## 217   5.552162e-04 -5.482085 5.483196 -8.384420 8.385530
## 218  -4.381286e-04 -5.483079 5.482203 -8.385414 8.384537
## 219   3.457332e-04 -5.482295 5.482987 -8.384630 8.385322
## 220  -2.728227e-04 -5.482914 5.482368 -8.385249 8.384703
## 221   2.152881e-04 -5.482426 5.482856 -8.384761 8.385191
## 222  -1.698867e-04 -5.482811 5.482471 -8.385146 8.384806
## 223   1.340599e-04 -5.482507 5.482775 -8.384842 8.385110
## 224  -1.057885e-04 -5.482747 5.482535 -8.385082 8.384870
## 225   8.347911e-05 -5.482558 5.482725 -8.384893 8.385060
## 226  -6.587449e-05 -5.482707 5.482575 -8.385042 8.384910
## 227   5.198245e-05 -5.482589 5.482693 -8.384924 8.385028
## 228  -4.102005e-05 -5.482682 5.482600 -8.385017 8.384935
## 229   3.236947e-05 -5.482609 5.482674 -8.384944 8.385009
## 230  -2.554319e-05 -5.482667 5.482616 -8.385002 8.384951
## 231   2.015647e-05 -5.482621 5.482661 -8.384956 8.384996
## 232  -1.590575e-05 -5.482657 5.482625 -8.384992 8.384960
## 233   1.255144e-05 -5.482629 5.482654 -8.384964 8.384989
## 234  -9.904509e-06 -5.482651 5.482631 -8.384986 8.384966
## 235   7.815781e-06 -5.482634 5.482649 -8.384968 8.384984
## 236  -6.167538e-06 -5.482647 5.482635 -8.384982 8.384970
## 237   4.866888e-06 -5.482636 5.482646 -8.384971 8.384981
## 238  -3.840527e-06 -5.482645 5.482637 -8.384980 8.384972
## 239   3.030611e-06 -5.482638 5.482644 -8.384973 8.384979
## 240  -2.391496e-06 -5.482644 5.482639 -8.384979 8.384974</code></pre>
<p>The ARIMA(1,0,3) is chosen as the best model because it has the
lowest AIC value. AIC stands for Akaike Information Criterion. It’s a
statistical method used for model selection. Models with lower AIC
values are generally considered preferable. They achieve a good balance
between fitting the data and being not overly complex.</p>
<pre class="r"><code>#Checking accuracy
sarima_acc &lt;- accuracy(forecast1, test_data)
sarima_acc</code></pre>
<pre><code>##                      ME     RMSE      MAE  MPE MAPE      MASE       ACF1
## Training set 0.07910448 2.804788 1.885204 -Inf  Inf 0.8450458 0.04032264
## Test set     0.86408795 5.414613 3.684651 -Inf  Inf 1.6516505         NA</code></pre>
<pre class="r"><code>summary(sarima_model)</code></pre>
<pre><code>## Series: train_data 
## ARIMA(1,0,3) with zero mean 
## 
## Coefficients:
##           ar1     ma1     ma2     ma3
##       -0.7891  1.7966  1.2845  0.4802
## s.e.   0.0791  0.1133  0.1447  0.0551
## 
## sigma^2 = 8.034:  log likelihood = -471.74
## AIC=953.48   AICc=953.8   BIC=969.77
## 
## Training set error measures:
##                      ME     RMSE      MAE  MPE MAPE      MASE       ACF1
## Training set 0.07910448 2.804788 1.885204 -Inf  Inf 0.8450458 0.04032264</code></pre>
<p>The “accuracy” and “summary” commands displays the various evaluation
metrics of the model. This includes, Mean Absolute Error, Root Mean
Squared Error etc.</p>
<pre class="r"><code>#Checking the residuala
checkresiduals(sarima_model)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-115-1.png" width="672" /></p>
<pre><code>## 
##  Ljung-Box test
## 
## data:  Residuals from ARIMA(1,0,3) with zero mean
## Q* = 34.446, df = 6, p-value = 5.516e-06
## 
## Model df: 4.   Total lags used: 10</code></pre>
<p>After checking the residuals, a p-value of less than 0.05 was
obtained, indicating the possible presence of autocorrelation
(dependence) in the residuals. This suggests that the null hypothesis
(no autocorrelation) can be rejected, meaning there is evidence of
remaining autocorrelation in the residuals.</p>
<p>After analysing the ACF plot, it is evident that there is still a
presence of two single significant spike. This indicates that there is
still autocorrelation in the errors. Essentially, it means that the
model is not making use of all the available data points.</p>
<p>To rectify this, we will conduct another seasonal ARIMA on the entire
time series data instead of splitting it into train and test data.</p>
<pre class="r"><code>acf(y1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-116-1.png" width="672" /></p>
<pre class="r"><code>pacf(y1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-117-1.png" width="672" /></p>
<pre class="r"><code>#Fitting a new SARIMA model
new_sarima &lt;-  auto.arima(y1, stepwise = FALSE, approximation = FALSE)</code></pre>
<pre class="r"><code>summary(new_sarima)</code></pre>
<pre><code>## Series: y1 
## ARIMA(3,0,1)(0,0,1)[8] with zero mean 
## 
## Coefficients:
##          ar1      ar2     ar3      ma1     sma1
##       1.6764  -1.0401  0.3056  -0.6548  -0.8240
## s.e.  0.1744   0.1790  0.0646   0.1752   0.0487
## 
## sigma^2 = 5.767:  log likelihood = -553.05
## AIC=1118.1   AICc=1118.46   BIC=1138.98
## 
## Training set error measures:
##                     ME    RMSE      MAE MPE MAPE      MASE       ACF1
## Training set 0.2108708 2.37632 1.620509 NaN  Inf 0.3164896 -0.0084813</code></pre>
<p>Although the the AIC value is just a little higher than the first
SARIMA, it doesn’t mean its a worse model. To determine its validity, we
check the residuals.</p>
<pre class="r"><code>checkresiduals(new_sarima)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-120-1.png" width="672" /></p>
<pre><code>## 
##  Ljung-Box test
## 
## data:  Residuals from ARIMA(3,0,1)(0,0,1)[8] with zero mean
## Q* = 11.141, df = 11, p-value = 0.4315
## 
## Model df: 5.   Total lags used: 16</code></pre>
<p>From the Ljung-Box test, the p-value is greater that 0.05. This
suggests a weaker presence of autocorrelation compared to a p-value less
than 0.05.</p>
<p>After analysing the residuals, it is evident that the ACF displays
only one significant lag spike beyond the reference line. This indicates
that the model is utilising most of the data points.</p>
<pre class="r"><code>#Forecasting
plot(forecast(new_sarima, h = 10))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-121-1.png" width="672" /></p>
</div>
</div>
</div>
</div>
<div id="limitations-of-the-analysis" class="section level1">
<h1>Limitations of the Analysis</h1>
<p>The most significant limitation arising from this analysis is the
restricted number of observations. A small dataset presents substantial
challenges, especially when employing machine learning techniques and
time series forecasting. When there are only a few data points, the
machine learning model may become too focused on the specific details of
the training data. This can result in overfitting, where the model works
well with the training data but struggles to accurately predict outcomes
with new, unseen data.</p>
</div>
<div id="discussion-and-conclusion" class="section level1">
<h1>Discussion and Conclusion</h1>
<p>After completing the analysis, we discovered some interesting
insights and patterns. For example, our analysis revealed that an
increase in humidity led to higher rainfall, while surface pressure and
temperature exhibited an inverse relationship. All of these findings
were obtained through simple statistical tests in multivariate analysis.
Improving on our analysis, we used machine learning techniques and
algorithms to uncover hidden patterns and make predictions based on
historical data. By training models on past weather observations, we
developed predictive capabilities that can forecast future conditions
with reasonable accuracy. These machine learning models are valuable
tools for stakeholders, providing insights into potential weather events
and supporting decision-making processes</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
